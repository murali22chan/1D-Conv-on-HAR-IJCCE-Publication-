{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_NWDODawnuZ"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout, Conv1D, MaxPooling1D\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ReduceLROnPlateau , ModelCheckpoint\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from keras.optimizers import SGD, RMSprop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhNEfA4Z7EX_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eebe35f3-0201-4378-9626-5b1a237c636c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtEqOHNc7KZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddd3f7f3-0592-42c8-99ee-c3985aba775d"
      },
      "source": [
        "!wget \"https://github.com/Reghunaath/Indian_food_dataset/raw/master/archive%20(1).zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-26 17:55:27--  https://github.com/Reghunaath/Indian_food_dataset/raw/master/archive%20(1).zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Reghunaath/Indian_food_dataset/master/archive%20(1).zip [following]\n",
            "--2021-03-26 17:55:27--  https://raw.githubusercontent.com/Reghunaath/Indian_food_dataset/master/archive%20(1).zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25693584 (25M) [application/zip]\n",
            "Saving to: ‘archive (1).zip.2’\n",
            "\n",
            "archive (1).zip.2   100%[===================>]  24.50M  52.2MB/s    in 0.5s    \n",
            "\n",
            "2021-03-26 17:55:28 (52.2 MB/s) - ‘archive (1).zip.2’ saved [25693584/25693584]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v2O_rRy8511",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d5b3da1-c536-45e4-8862-0f33bc705ede"
      },
      "source": [
        "!unzip \"/content/archive (1).zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/archive (1).zip\n",
            "replace test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: test.csv                \n",
            "replace train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8NCKs9kzaYk"
      },
      "source": [
        "test = pd.read_csv(\"/content/test.csv\")\n",
        "df = pd.read_csv(\"/content/train.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu5CupXKz5Ku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b59bc567-5faf-4f77-dd51-daa72e97739a"
      },
      "source": [
        "print(df.shape , test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7352, 563) (2947, 563)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbAOu4Ze0Dq2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e3e0c62-08c6-423f-930d-af3ceeafc8d3"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(df.iloc[:,0:562])\n",
        "mat_train = scaler.transform(df.iloc[:,0:562])\n",
        "print(mat_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.64429225 0.48985291 0.43354743 ... 0.79825103 0.47068654 0.        ]\n",
            " [0.63920942 0.49179472 0.4382399  ... 0.79848665 0.47284164 0.        ]\n",
            " [0.63982653 0.49026642 0.44326915 ... 0.79872236 0.47544109 0.        ]\n",
            " ...\n",
            " [0.63669369 0.49149469 0.47748909 ... 0.84506893 0.52040559 1.        ]\n",
            " [0.64482708 0.49057848 0.42085971 ... 0.84323381 0.51266974 1.        ]\n",
            " [0.67575173 0.49378844 0.39806642 ... 0.84348837 0.51834742 1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvKWguXz0F73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e85b745-6e9c-47dc-b985-29dff00383dc"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "scaler.fit(test.iloc[:,0:562])\n",
        "mat_test = scaler.transform(test.iloc[:,0:562])\n",
        "print(mat_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.6718788  0.55764282 0.52464834 ... 0.62209457 0.46362736 0.        ]\n",
            " [0.69470427 0.57426358 0.42707858 ... 0.62446791 0.45014396 0.        ]\n",
            " [0.68636345 0.55310221 0.42794829 ... 0.62380956 0.45251181 0.        ]\n",
            " ...\n",
            " [0.74529355 0.64526771 0.43015674 ... 0.62088108 0.58803909 1.        ]\n",
            " [0.65638384 0.62620241 0.44817885 ... 0.61581385 0.59135763 1.        ]\n",
            " [0.58994885 0.56560474 0.41032069 ... 0.61537208 0.59163879 1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI-gtLRh0IYT"
      },
      "source": [
        "temp = []\n",
        "for i in df.Activity:\n",
        "    if i == \"WALKING\": temp.append(3)\n",
        "    if i == \"WALKING_UPSTAIRS\": temp.append(5)\n",
        "    if i == \"WALKING_DOWNSTAIRS\": temp.append(4)\n",
        "    if i == \"SITTING\": temp.append(1)\n",
        "    if i == \"STANDING\": temp.append(2)\n",
        "    if i == \"LAYING\": temp.append(0)\n",
        "df[\"n_Activity\"] = temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlH6-kqn0MDJ"
      },
      "source": [
        "temp = []\n",
        "for i in test.Activity:\n",
        "    if i == \"WALKING\": temp.append(3)\n",
        "    if i == \"WALKING_UPSTAIRS\": temp.append(5)\n",
        "    if i == \"WALKING_DOWNSTAIRS\": temp.append(4)\n",
        "    if i == \"SITTING\": temp.append(1)\n",
        "    if i == \"STANDING\": temp.append(2)\n",
        "    if i == \"LAYING\": temp.append(0)\n",
        "test[\"n_Activity\"] = temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zV3fMTtK0Nro"
      },
      "source": [
        "df.drop([\"Activity\"] , axis = 1 , inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qowwnPD0PeK"
      },
      "source": [
        "test.drop([\"Activity\"] , axis = 1 , inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfI0ANqE0RnU"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(df.n_Activity , num_classes=6)\n",
        "y_test = to_categorical(test.n_Activity , num_classes=6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYFQ9dXaWLxj"
      },
      "source": [
        "integer_y_test = test.n_Activity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VaqmXWkC0Tdg"
      },
      "source": [
        "X_train = mat_train \n",
        "X_test = mat_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWnxEoAo0VNa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3dfc80b5-684d-4a4e-febd-de1c7f51e1cd"
      },
      "source": [
        "print(X_train.shape , y_train.shape)\n",
        "print(X_test.shape , y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7352, 562) (7352, 6)\n",
            "(2947, 562) (2947, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahwbw-kM0W0W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a912db5-1051-49ec-866d-c649f1c29a5e"
      },
      "source": [
        "filepath=\"HAR_weights.hdf5\"\n",
        "from keras.callbacks import ReduceLROnPlateau , ModelCheckpoint\n",
        "\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.1, epsilon=0.0001, patience=1, verbose=1)\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqubYXVOEHS5"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        if(logs.get('val_accuracy') > 0.93):   \n",
        "          print(\"\\nReached %2.2f%% accuracy, so stopping training!!\" %(93))   \n",
        "          self.model.stop_training = True\n",
        "callback = myCallback()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pblP_z8h0bxu"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout , BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import RMSprop, Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_tRbFro0eyZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca8466f2-3270-4565-9ca4-49a74281e219"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(64, input_dim=X_train.shape[1] , activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(196, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(6, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer = Adam(lr = 0.001),loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_12 (Dense)             (None, 64)                36032     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 196)               25284     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 32)                6304      \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 6)                 198       \n",
            "=================================================================\n",
            "Total params: 80,554\n",
            "Trainable params: 80,426\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grTHy8qO0gZN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea7bdc45-33b1-4950-d7be-517ae502019e"
      },
      "source": [
        "model.fit(X_train, y_train , epochs=200 , batch_size = 128 , validation_data=(X_test, y_test) , callbacks=[callback,checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "58/58 [==============================] - 1s 10ms/step - loss: 0.8155 - accuracy: 0.6973 - val_loss: 0.8375 - val_accuracy: 0.5755\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.57550, saving model to HAR_weights.hdf5\n",
            "Epoch 2/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.1339 - accuracy: 0.9436 - val_loss: 0.6821 - val_accuracy: 0.7180\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.57550 to 0.71802, saving model to HAR_weights.hdf5\n",
            "Epoch 3/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.1028 - accuracy: 0.9603 - val_loss: 0.5160 - val_accuracy: 0.7743\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.71802 to 0.77435, saving model to HAR_weights.hdf5\n",
            "Epoch 4/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0859 - accuracy: 0.9652 - val_loss: 0.3076 - val_accuracy: 0.8602\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.77435 to 0.86020, saving model to HAR_weights.hdf5\n",
            "Epoch 5/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0718 - accuracy: 0.9708 - val_loss: 0.3041 - val_accuracy: 0.8748\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.86020 to 0.87479, saving model to HAR_weights.hdf5\n",
            "Epoch 6/200\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0530 - accuracy: 0.9781 - val_loss: 0.4383 - val_accuracy: 0.8388\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.87479\n",
            "Epoch 7/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0395 - accuracy: 0.9849 - val_loss: 0.5211 - val_accuracy: 0.8337\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.87479\n",
            "Epoch 8/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0376 - accuracy: 0.9858 - val_loss: 0.7349 - val_accuracy: 0.8083\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.87479\n",
            "Epoch 9/200\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0430 - accuracy: 0.9822 - val_loss: 1.4381 - val_accuracy: 0.7567\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.87479\n",
            "Epoch 10/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0356 - accuracy: 0.9864 - val_loss: 0.6445 - val_accuracy: 0.8317\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.87479\n",
            "Epoch 11/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0358 - accuracy: 0.9862 - val_loss: 0.8194 - val_accuracy: 0.7974\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.87479\n",
            "Epoch 12/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0331 - accuracy: 0.9880 - val_loss: 0.5602 - val_accuracy: 0.8229\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.87479\n",
            "Epoch 13/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0523 - accuracy: 0.9804 - val_loss: 0.7915 - val_accuracy: 0.8307\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.87479\n",
            "Epoch 14/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0416 - accuracy: 0.9831 - val_loss: 0.3134 - val_accuracy: 0.9165\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.87479 to 0.91653, saving model to HAR_weights.hdf5\n",
            "Epoch 15/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0469 - accuracy: 0.9843 - val_loss: 0.4338 - val_accuracy: 0.8653\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.91653\n",
            "Epoch 16/200\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0329 - accuracy: 0.9868 - val_loss: 0.4285 - val_accuracy: 0.8683\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.91653\n",
            "Epoch 17/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0259 - accuracy: 0.9894 - val_loss: 0.3463 - val_accuracy: 0.9023\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.91653\n",
            "Epoch 18/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0256 - accuracy: 0.9914 - val_loss: 0.6349 - val_accuracy: 0.8361\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.91653\n",
            "Epoch 19/200\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0245 - accuracy: 0.9914 - val_loss: 0.2817 - val_accuracy: 0.9175\n",
            "\n",
            "Epoch 00019: val_accuracy improved from 0.91653 to 0.91754, saving model to HAR_weights.hdf5\n",
            "Epoch 20/200\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0338 - accuracy: 0.9880 - val_loss: 1.0220 - val_accuracy: 0.8473\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.91754\n",
            "Epoch 21/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0393 - accuracy: 0.9868 - val_loss: 0.4879 - val_accuracy: 0.8670\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.91754\n",
            "Epoch 22/200\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0226 - accuracy: 0.9924 - val_loss: 0.4946 - val_accuracy: 0.9186\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.91754 to 0.91856, saving model to HAR_weights.hdf5\n",
            "Epoch 23/200\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0406 - accuracy: 0.9836 - val_loss: 0.5861 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.91856\n",
            "Epoch 24/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0237 - accuracy: 0.9924 - val_loss: 0.7286 - val_accuracy: 0.8195\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.91856\n",
            "Epoch 25/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0398 - accuracy: 0.9859 - val_loss: 1.2934 - val_accuracy: 0.7947\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.91856\n",
            "Epoch 26/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0318 - accuracy: 0.9874 - val_loss: 2.0305 - val_accuracy: 0.7849\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.91856\n",
            "Epoch 27/200\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0235 - accuracy: 0.9912 - val_loss: 0.6586 - val_accuracy: 0.8497\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.91856\n",
            "Epoch 28/200\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0176 - accuracy: 0.9923 - val_loss: 0.7790 - val_accuracy: 0.8453\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.91856\n",
            "Epoch 29/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0171 - accuracy: 0.9939 - val_loss: 0.5120 - val_accuracy: 0.8802\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.91856\n",
            "Epoch 30/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.4796 - val_accuracy: 0.8979\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.91856\n",
            "Epoch 31/200\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0326 - accuracy: 0.9878 - val_loss: 0.7255 - val_accuracy: 0.8711\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.91856\n",
            "Epoch 32/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0159 - accuracy: 0.9943 - val_loss: 0.3780 - val_accuracy: 0.9199\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.91856 to 0.91992, saving model to HAR_weights.hdf5\n",
            "Epoch 33/200\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0160 - accuracy: 0.9937 - val_loss: 0.9980 - val_accuracy: 0.8320\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.91992\n",
            "Epoch 34/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0192 - accuracy: 0.9925 - val_loss: 0.8466 - val_accuracy: 0.8276\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.91992\n",
            "Epoch 35/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0122 - accuracy: 0.9942 - val_loss: 1.4906 - val_accuracy: 0.7570\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.91992\n",
            "Epoch 36/200\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.7850 - val_accuracy: 0.8527\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.91992\n",
            "Epoch 37/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 1.1071 - val_accuracy: 0.8280\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.91992\n",
            "Epoch 38/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.4135 - val_accuracy: 0.9087\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.91992\n",
            "Epoch 39/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0103 - accuracy: 0.9963 - val_loss: 0.8135 - val_accuracy: 0.8605\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.91992\n",
            "Epoch 40/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 1.7411 - val_accuracy: 0.7615\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.91992\n",
            "Epoch 41/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 0.9968 - val_loss: 2.6250 - val_accuracy: 0.6736\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.91992\n",
            "Epoch 42/200\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0129 - accuracy: 0.9949 - val_loss: 1.2918 - val_accuracy: 0.8174\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.91992\n",
            "Epoch 43/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 0.7408 - val_accuracy: 0.8470\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.91992\n",
            "Epoch 44/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0190 - accuracy: 0.9947 - val_loss: 0.9855 - val_accuracy: 0.8168\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.91992\n",
            "Epoch 45/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0197 - accuracy: 0.9926 - val_loss: 1.0096 - val_accuracy: 0.8134\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.91992\n",
            "Epoch 46/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0209 - accuracy: 0.9922 - val_loss: 0.7426 - val_accuracy: 0.8490\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.91992\n",
            "Epoch 47/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 1.6044 - val_accuracy: 0.7255\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.91992\n",
            "Epoch 48/200\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.8681 - val_accuracy: 0.8409\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.91992\n",
            "Epoch 49/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.6183 - val_accuracy: 0.8724\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.91992\n",
            "Epoch 50/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0057 - accuracy: 0.9979 - val_loss: 0.7202 - val_accuracy: 0.8677\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.91992\n",
            "Epoch 51/200\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.8122 - val_accuracy: 0.8317\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.91992\n",
            "Epoch 52/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0102 - accuracy: 0.9957 - val_loss: 0.8085 - val_accuracy: 0.8629\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.91992\n",
            "Epoch 53/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0097 - accuracy: 0.9973 - val_loss: 2.2110 - val_accuracy: 0.7265\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.91992\n",
            "Epoch 54/200\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0070 - accuracy: 0.9974 - val_loss: 0.8347 - val_accuracy: 0.8405\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.91992\n",
            "Epoch 55/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0164 - accuracy: 0.9941 - val_loss: 0.7216 - val_accuracy: 0.8755\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.91992\n",
            "Epoch 56/200\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.6960 - val_accuracy: 0.8880\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.91992\n",
            "Epoch 57/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.6793 - val_accuracy: 0.8724\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.91992\n",
            "Epoch 58/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0090 - accuracy: 0.9974 - val_loss: 1.0051 - val_accuracy: 0.8324\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.91992\n",
            "Epoch 59/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0097 - accuracy: 0.9964 - val_loss: 2.0144 - val_accuracy: 0.7913\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.91992\n",
            "Epoch 60/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.8182 - val_accuracy: 0.8704\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.91992\n",
            "Epoch 61/200\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.8866 - val_accuracy: 0.8483\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.91992\n",
            "Epoch 62/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.4866 - val_accuracy: 0.9084\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.91992\n",
            "Epoch 63/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 0.5440 - val_accuracy: 0.9125\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.91992\n",
            "Epoch 64/200\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 0.9977 - val_loss: 1.1840 - val_accuracy: 0.8242\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.91992\n",
            "Epoch 65/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.8956 - val_accuracy: 0.8588\n",
            "\n",
            "Epoch 00065: val_accuracy did not improve from 0.91992\n",
            "Epoch 66/200\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 1.1864 - val_accuracy: 0.8347\n",
            "\n",
            "Epoch 00066: val_accuracy did not improve from 0.91992\n",
            "Epoch 67/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 1.1826 - val_accuracy: 0.8402\n",
            "\n",
            "Epoch 00067: val_accuracy did not improve from 0.91992\n",
            "Epoch 68/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0448 - accuracy: 0.9907 - val_loss: 1.5189 - val_accuracy: 0.7723\n",
            "\n",
            "Epoch 00068: val_accuracy did not improve from 0.91992\n",
            "Epoch 69/200\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0151 - accuracy: 0.9956 - val_loss: 4.0486 - val_accuracy: 0.4818\n",
            "\n",
            "Epoch 00069: val_accuracy did not improve from 0.91992\n",
            "Epoch 70/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 2.9701 - val_accuracy: 0.5738\n",
            "\n",
            "Epoch 00070: val_accuracy did not improve from 0.91992\n",
            "Epoch 71/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 0.9972 - val_loss: 0.7337 - val_accuracy: 0.8368\n",
            "\n",
            "Epoch 00071: val_accuracy did not improve from 0.91992\n",
            "Epoch 72/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0155 - accuracy: 0.9942 - val_loss: 0.5178 - val_accuracy: 0.8887\n",
            "\n",
            "Epoch 00072: val_accuracy did not improve from 0.91992\n",
            "Epoch 73/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0122 - accuracy: 0.9953 - val_loss: 0.6579 - val_accuracy: 0.8653\n",
            "\n",
            "Epoch 00073: val_accuracy did not improve from 0.91992\n",
            "Epoch 74/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0130 - accuracy: 0.9961 - val_loss: 0.4511 - val_accuracy: 0.8870\n",
            "\n",
            "Epoch 00074: val_accuracy did not improve from 0.91992\n",
            "Epoch 75/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0182 - accuracy: 0.9938 - val_loss: 1.4588 - val_accuracy: 0.7682\n",
            "\n",
            "Epoch 00075: val_accuracy did not improve from 0.91992\n",
            "Epoch 76/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0036 - accuracy: 0.9990 - val_loss: 0.4964 - val_accuracy: 0.8870\n",
            "\n",
            "Epoch 00076: val_accuracy did not improve from 0.91992\n",
            "Epoch 77/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 0.8992 - val_accuracy: 0.8402\n",
            "\n",
            "Epoch 00077: val_accuracy did not improve from 0.91992\n",
            "Epoch 78/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.7607 - val_accuracy: 0.8514\n",
            "\n",
            "Epoch 00078: val_accuracy did not improve from 0.91992\n",
            "Epoch 79/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 0.6356 - val_accuracy: 0.8843\n",
            "\n",
            "Epoch 00079: val_accuracy did not improve from 0.91992\n",
            "Epoch 80/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 1.1393 - val_accuracy: 0.8181\n",
            "\n",
            "Epoch 00080: val_accuracy did not improve from 0.91992\n",
            "Epoch 81/200\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 0.9983 - val_loss: 0.9181 - val_accuracy: 0.8439\n",
            "\n",
            "Epoch 00081: val_accuracy did not improve from 0.91992\n",
            "Epoch 82/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.7093 - val_accuracy: 0.8717\n",
            "\n",
            "Epoch 00082: val_accuracy did not improve from 0.91992\n",
            "Epoch 83/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.7386 - val_accuracy: 0.8717\n",
            "\n",
            "Epoch 00083: val_accuracy did not improve from 0.91992\n",
            "Epoch 84/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 1.1849 - val_accuracy: 0.8242\n",
            "\n",
            "Epoch 00084: val_accuracy did not improve from 0.91992\n",
            "Epoch 85/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 1.4031 - val_accuracy: 0.8130\n",
            "\n",
            "Epoch 00085: val_accuracy did not improve from 0.91992\n",
            "Epoch 86/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0074 - accuracy: 0.9971 - val_loss: 1.9124 - val_accuracy: 0.7526\n",
            "\n",
            "Epoch 00086: val_accuracy did not improve from 0.91992\n",
            "Epoch 87/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.8716 - val_accuracy: 0.8636\n",
            "\n",
            "Epoch 00087: val_accuracy did not improve from 0.91992\n",
            "Epoch 88/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0075 - accuracy: 0.9972 - val_loss: 0.4692 - val_accuracy: 0.9121\n",
            "\n",
            "Epoch 00088: val_accuracy did not improve from 0.91992\n",
            "Epoch 89/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.8292 - val_accuracy: 0.8660\n",
            "\n",
            "Epoch 00089: val_accuracy did not improve from 0.91992\n",
            "Epoch 90/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 2.0556 - val_accuracy: 0.7146\n",
            "\n",
            "Epoch 00090: val_accuracy did not improve from 0.91992\n",
            "Epoch 91/200\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0119 - accuracy: 0.9938 - val_loss: 2.0723 - val_accuracy: 0.7224\n",
            "\n",
            "Epoch 00091: val_accuracy did not improve from 0.91992\n",
            "Epoch 92/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0090 - accuracy: 0.9958 - val_loss: 1.2493 - val_accuracy: 0.7927\n",
            "\n",
            "Epoch 00092: val_accuracy did not improve from 0.91992\n",
            "Epoch 93/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0307 - accuracy: 0.9914 - val_loss: 0.3807 - val_accuracy: 0.9101\n",
            "\n",
            "Epoch 00093: val_accuracy did not improve from 0.91992\n",
            "Epoch 94/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.4362 - val_accuracy: 0.9067\n",
            "\n",
            "Epoch 00094: val_accuracy did not improve from 0.91992\n",
            "Epoch 95/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.6369 - val_accuracy: 0.8843\n",
            "\n",
            "Epoch 00095: val_accuracy did not improve from 0.91992\n",
            "Epoch 96/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.8517 - val_accuracy: 0.8466\n",
            "\n",
            "Epoch 00096: val_accuracy did not improve from 0.91992\n",
            "Epoch 97/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.7518 - val_accuracy: 0.8758\n",
            "\n",
            "Epoch 00097: val_accuracy did not improve from 0.91992\n",
            "Epoch 98/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 8.2436e-04 - accuracy: 0.9998 - val_loss: 1.0961 - val_accuracy: 0.8337\n",
            "\n",
            "Epoch 00098: val_accuracy did not improve from 0.91992\n",
            "Epoch 99/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 0.9982 - val_loss: 1.2449 - val_accuracy: 0.8076\n",
            "\n",
            "Epoch 00099: val_accuracy did not improve from 0.91992\n",
            "Epoch 100/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.4966 - val_accuracy: 0.9006\n",
            "\n",
            "Epoch 00100: val_accuracy did not improve from 0.91992\n",
            "Epoch 101/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.5095 - val_accuracy: 0.9063\n",
            "\n",
            "Epoch 00101: val_accuracy did not improve from 0.91992\n",
            "Epoch 102/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.4771 - val_accuracy: 0.9091\n",
            "\n",
            "Epoch 00102: val_accuracy did not improve from 0.91992\n",
            "Epoch 103/200\n",
            "58/58 [==============================] - 0s 5ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.6131 - val_accuracy: 0.8802\n",
            "\n",
            "Epoch 00103: val_accuracy did not improve from 0.91992\n",
            "Epoch 104/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 9.3437e-04 - accuracy: 0.9997 - val_loss: 0.7475 - val_accuracy: 0.8782\n",
            "\n",
            "Epoch 00104: val_accuracy did not improve from 0.91992\n",
            "Epoch 105/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0010 - accuracy: 0.9993 - val_loss: 0.7556 - val_accuracy: 0.8690\n",
            "\n",
            "Epoch 00105: val_accuracy did not improve from 0.91992\n",
            "Epoch 106/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.8429 - val_accuracy: 0.8761\n",
            "\n",
            "Epoch 00106: val_accuracy did not improve from 0.91992\n",
            "Epoch 107/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 2.6111 - val_accuracy: 0.7089\n",
            "\n",
            "Epoch 00107: val_accuracy did not improve from 0.91992\n",
            "Epoch 108/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0030 - accuracy: 0.9982 - val_loss: 1.2744 - val_accuracy: 0.8185\n",
            "\n",
            "Epoch 00108: val_accuracy did not improve from 0.91992\n",
            "Epoch 109/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0080 - accuracy: 0.9971 - val_loss: 0.7339 - val_accuracy: 0.8918\n",
            "\n",
            "Epoch 00109: val_accuracy did not improve from 0.91992\n",
            "Epoch 110/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0216 - accuracy: 0.9929 - val_loss: 2.1682 - val_accuracy: 0.7370\n",
            "\n",
            "Epoch 00110: val_accuracy did not improve from 0.91992\n",
            "Epoch 111/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 0.6235 - val_accuracy: 0.8928\n",
            "\n",
            "Epoch 00111: val_accuracy did not improve from 0.91992\n",
            "Epoch 112/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 1.8136 - val_accuracy: 0.7397\n",
            "\n",
            "Epoch 00112: val_accuracy did not improve from 0.91992\n",
            "Epoch 113/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 0.9973 - val_loss: 1.0758 - val_accuracy: 0.8266\n",
            "\n",
            "Epoch 00113: val_accuracy did not improve from 0.91992\n",
            "Epoch 114/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.6930 - val_accuracy: 0.8782\n",
            "\n",
            "Epoch 00114: val_accuracy did not improve from 0.91992\n",
            "Epoch 115/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0047 - accuracy: 0.9984 - val_loss: 1.2802 - val_accuracy: 0.8113\n",
            "\n",
            "Epoch 00115: val_accuracy did not improve from 0.91992\n",
            "Epoch 116/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0155 - accuracy: 0.9952 - val_loss: 2.3784 - val_accuracy: 0.7160\n",
            "\n",
            "Epoch 00116: val_accuracy did not improve from 0.91992\n",
            "Epoch 117/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0199 - accuracy: 0.9929 - val_loss: 0.6589 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 00117: val_accuracy did not improve from 0.91992\n",
            "Epoch 118/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.5817 - val_accuracy: 0.8795\n",
            "\n",
            "Epoch 00118: val_accuracy did not improve from 0.91992\n",
            "Epoch 119/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0111 - accuracy: 0.9980 - val_loss: 0.5587 - val_accuracy: 0.8921\n",
            "\n",
            "Epoch 00119: val_accuracy did not improve from 0.91992\n",
            "Epoch 120/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 0.9979 - val_loss: 1.0294 - val_accuracy: 0.8252\n",
            "\n",
            "Epoch 00120: val_accuracy did not improve from 0.91992\n",
            "Epoch 121/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 1.1456 - val_accuracy: 0.8300\n",
            "\n",
            "Epoch 00121: val_accuracy did not improve from 0.91992\n",
            "Epoch 122/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.7723 - val_accuracy: 0.8890\n",
            "\n",
            "Epoch 00122: val_accuracy did not improve from 0.91992\n",
            "Epoch 123/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.9985 - val_loss: 1.0689 - val_accuracy: 0.8392\n",
            "\n",
            "Epoch 00123: val_accuracy did not improve from 0.91992\n",
            "Epoch 124/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.9565 - val_accuracy: 0.8466\n",
            "\n",
            "Epoch 00124: val_accuracy did not improve from 0.91992\n",
            "Epoch 125/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.8819 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 00125: val_accuracy did not improve from 0.91992\n",
            "Epoch 126/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 1.0189 - val_accuracy: 0.8531\n",
            "\n",
            "Epoch 00126: val_accuracy did not improve from 0.91992\n",
            "Epoch 127/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 1.0724 - val_accuracy: 0.8558\n",
            "\n",
            "Epoch 00127: val_accuracy did not improve from 0.91992\n",
            "Epoch 128/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.9470 - val_accuracy: 0.8588\n",
            "\n",
            "Epoch 00128: val_accuracy did not improve from 0.91992\n",
            "Epoch 129/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 0.9986 - val_loss: 1.6827 - val_accuracy: 0.7896\n",
            "\n",
            "Epoch 00129: val_accuracy did not improve from 0.91992\n",
            "Epoch 130/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.8881 - val_accuracy: 0.8690\n",
            "\n",
            "Epoch 00130: val_accuracy did not improve from 0.91992\n",
            "Epoch 131/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 8.1313e-04 - accuracy: 0.9997 - val_loss: 1.5106 - val_accuracy: 0.8273\n",
            "\n",
            "Epoch 00131: val_accuracy did not improve from 0.91992\n",
            "Epoch 132/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 1.3496 - val_accuracy: 0.8368\n",
            "\n",
            "Epoch 00132: val_accuracy did not improve from 0.91992\n",
            "Epoch 133/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 0.9985 - val_loss: 1.1455 - val_accuracy: 0.8361\n",
            "\n",
            "Epoch 00133: val_accuracy did not improve from 0.91992\n",
            "Epoch 134/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0215 - accuracy: 0.9941 - val_loss: 2.2312 - val_accuracy: 0.6844\n",
            "\n",
            "Epoch 00134: val_accuracy did not improve from 0.91992\n",
            "Epoch 135/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 1.7852 - val_accuracy: 0.7754\n",
            "\n",
            "Epoch 00135: val_accuracy did not improve from 0.91992\n",
            "Epoch 136/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0053 - accuracy: 0.9974 - val_loss: 1.3525 - val_accuracy: 0.8198\n",
            "\n",
            "Epoch 00136: val_accuracy did not improve from 0.91992\n",
            "Epoch 137/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 1.3864 - val_accuracy: 0.8205\n",
            "\n",
            "Epoch 00137: val_accuracy did not improve from 0.91992\n",
            "Epoch 138/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0054 - accuracy: 0.9985 - val_loss: 1.1760 - val_accuracy: 0.8219\n",
            "\n",
            "Epoch 00138: val_accuracy did not improve from 0.91992\n",
            "Epoch 139/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 1.1514 - val_accuracy: 0.8361\n",
            "\n",
            "Epoch 00139: val_accuracy did not improve from 0.91992\n",
            "Epoch 140/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 0.9993 - val_loss: 0.9487 - val_accuracy: 0.8646\n",
            "\n",
            "Epoch 00140: val_accuracy did not improve from 0.91992\n",
            "Epoch 141/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 6.7910e-04 - accuracy: 0.9999 - val_loss: 1.8240 - val_accuracy: 0.7771\n",
            "\n",
            "Epoch 00141: val_accuracy did not improve from 0.91992\n",
            "Epoch 142/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 1.9677 - val_accuracy: 0.7964\n",
            "\n",
            "Epoch 00142: val_accuracy did not improve from 0.91992\n",
            "Epoch 143/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0312 - accuracy: 0.9927 - val_loss: 1.0476 - val_accuracy: 0.8012\n",
            "\n",
            "Epoch 00143: val_accuracy did not improve from 0.91992\n",
            "Epoch 144/200\n",
            "58/58 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.3477 - val_accuracy: 0.9338\n",
            "\n",
            "Reached 93.00% accuracy, so stopping training!!\n",
            "\n",
            "Epoch 00144: val_accuracy improved from 0.91992 to 0.93383, saving model to HAR_weights.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd383522490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnygHlb60kNV"
      },
      "source": [
        "model.save(\"NN93.48.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIPFySabRezb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50a5f464-068d-4aa9-d80e-4e744a805246"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93/93 [==============================] - 0s 1ms/step - loss: 0.3477 - accuracy: 0.9338\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.34773972630500793, 0.9338310360908508]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyMhB9jJG-oq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d40d436-5831-40a6-af46-f9388f35977c"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_pred = model.predict(X_test)\n",
        "# y_pred.shape\n",
        "classification_report(integer_y_test, np.argmax(y_pred, axis = 1), output_dict=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': {'f1-score': 0.9916897506925207,\n",
              "  'precision': 0.9835164835164835,\n",
              "  'recall': 1.0,\n",
              "  'support': 537},\n",
              " '1': {'f1-score': 0.918974358974359,\n",
              "  'precision': 0.9256198347107438,\n",
              "  'recall': 0.9124236252545825,\n",
              "  'support': 491},\n",
              " '2': {'f1-score': 0.9283018867924527,\n",
              "  'precision': 0.9318181818181818,\n",
              "  'recall': 0.924812030075188,\n",
              "  'support': 532},\n",
              " '3': {'f1-score': 0.9172113289760349,\n",
              "  'precision': 0.9976303317535545,\n",
              "  'recall': 0.8487903225806451,\n",
              "  'support': 496},\n",
              " '4': {'f1-score': 0.9480198019801981,\n",
              "  'precision': 0.9871134020618557,\n",
              "  'recall': 0.9119047619047619,\n",
              "  'support': 420},\n",
              " '5': {'f1-score': 0.8971428571428571,\n",
              "  'precision': 0.8134715025906736,\n",
              "  'recall': 1.0,\n",
              "  'support': 471},\n",
              " 'accuracy': 0.9338310145911096,\n",
              " 'macro avg': {'f1-score': 0.9335566640930703,\n",
              "  'precision': 0.9398616227419155,\n",
              "  'recall': 0.9329884566358629,\n",
              "  'support': 2947},\n",
              " 'weighted avg': {'f1-score': 0.9342619042653412,\n",
              "  'precision': 0.9402484948607224,\n",
              "  'recall': 0.9338310145911096,\n",
              "  'support': 2947}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iNpE8vWk_xM",
        "outputId": "c0612064-7a43-4c4c-ec01-e9001341536b"
      },
      "source": [
        "test = pd.read_csv(\"/content/test.csv\")\n",
        "train = pd.read_csv(\"/content/train.csv\")\n",
        "X_train = train.iloc[:, : -2]\n",
        "y_train = train.iloc[:, 562:563]\n",
        "X_test = test.iloc[:, : -2]\n",
        "y_test = test.iloc[:, 562:563]\n",
        "label_encoder = LabelEncoder()\n",
        "integer_y_train = label_encoder.fit_transform(y_train)\n",
        "integer_y_test = label_encoder.transform(y_test)\n",
        "one_hot_y_train = to_categorical(integer_y_train, 6)\n",
        "one_hot_y_test = to_categorical(integer_y_test, 6)\n",
        "X_train = np.expand_dims(X_train,axis=1)\n",
        "X_test = np.expand_dims(X_test,axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:251: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ5oo4SKj_o7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        },
        "outputId": "9d9020ce-1d5c-4aed-d2e1-348fad06ad06"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "def plot_confusion_matrix(cm,lables):\n",
        "    fig, ax = plt.subplots(figsize=(12,8)) # for plotting confusion matrix as image\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "    yticks=np.arange(cm.shape[0]),\n",
        "    xticklabels=lables, yticklabels=lables,\n",
        "    ylabel='True label',\n",
        "    xlabel='Predicted label')\n",
        "    plt.xticks(rotation = 90)\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, int(cm[i, j]),ha=\"center\", va=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()\n",
        "integer_y_pred = np.argmax(y_pred, axis = 1)\n",
        "string_y_pred = label_encoder.inverse_transform(integer_y_pred)\n",
        "cm = confusion_matrix(y_test,string_y_pred)\n",
        "plot_confusion_matrix(cm, np.unique(string_y_pred)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAo8AAAI4CAYAAAALXwO2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZxWZd348c8XEFxQSUWTAVPAFRcUVMQNXEHALU19LCE19UkzUyvLFlv0Mc1Is8XSHq3Hn1vuuKG4L4iguJJKigm4gApuIDBcvz/uM3TLDDM3OmfOcM/n3et+cc51rnPO91xZfvleZ4mUEpIkSVIl2hUdgCRJklYcJo+SJEmqmMmjJEmSKmbyKEmSpIqZPEqSJKliHYoOQNUjOqySouPqRYfRqmy7+QZFhyBJVe3JJyfNTil1LTqOZWm/xpdSWjSvWY+Z5s26K6U0pFkPuhxMHtVsouPqdNr0K0WH0ao88vjFRYcgSVVtlZXitaJjaExaNK/Z/904f/Lv12nWAy4np60lSZJUMSuPkiRJuQmI6qrVmTxKkiTlJYCIoqNoVtWVCkuSJClXVh4lSZLy5LS1JEmSKua0tSRJktoqK4+SJEm5qb6nravraiRJkpQrK4+SJEl5qrJ7Hk0eJUmS8hI4bS1JkqS2y8qjJElSbsJpa0mSJC0Hp60lSZLUVll5lCRJylOVTVtbeZQkSVLFrDxKkiTlpvq+MGPyKEmSlJfAaWtJkiS1XVYeJUmS8lRl09bVdTWSJEnKlZVHSZKk3PjAjCRJkpZHOx+YkSRJUisVEdMi4tmImBwRE7O2tSLi7oh4OfvzC1l7RMRFETE1Ip6JiO2aOr7JoyRJUl6C0rR1c/4qMzil1Del1D9bPwMYl1LaGBiXrQMMBTbOfscBf2zqwCaPkiRJeYpo3t9ncwBwRbZ8BXBgWfvfUsl4oEtErN/YgUweJUmSVizrRMTEst9xS21PwNiImFS2bb2U0hvZ8pvAetlyDfB62b7Ts7Zl8oEZSZKk3OTytPXssunohuySUpoREesCd0fEP8s3ppRSRKTPenIrj1oh/fO2n/HEtT9k/NVn8PCV3wPgJ98cxoRrfsD4q8/g1j+cyPpd1wTgO0ftyfirz2D81Wcw8bof8uHEi/jCGqsWGX6LGnvXnWzdZ1P6bNab8887t+hwWgXHpD7HpD7HpGGOS+uXUpqR/fk2cCOwA/BW3XR09ufbWfcZQI+y3btnbctk8rgCiIgPG9n224iYERHtImLliPhnRGxVtv27EXFJRGwYEc9lbYMiIkXEiLJ+YyJiULbcISLOyZ7Impz9zszxEj+TIcddyIDDz2WXI88DYPQV49jhsP9hwOHncsdDz/GD44aW2v82jgGHn8uAw8/lJ7+7hYcmvcx7739cZOgtpra2llNOPpGbb72Dp555geuuvoopL7xQdFiFckzqc0zqc0wa5rh8Ri14z2NErBYRq9ctA/sAzwG3ACOzbiOBm7PlW4CjsqeuBwBzy6a3G2TyuAKLiHbAQZTuVdg9pTQfOAX4Q/YPQQ1wAv95oqrcdGBZCeEvgW7AVimlvsCuwErNHX9z++Cj+UuWV12lEynVr8h/ZUh/rr1zUkuGVagnJkygV6/ebNSzJx07duTQww5nzK03N71jFXNM6nNM6nNMGua4fEYt+7T1esDDEfE0MAG4LaV0J3AusHdEvAzsla0D3A68AkwF/gJ8s6kTeM/jim0Q8DxwDXAEcF9K6c6IOBo4ChgGnJVSei8i1lxq36eBlSJi75TS3XWNEbEq8A1gwywZJaX0AXBW3hezPFJK3PqHk0gpcdn1j/DXGx4B4KwTR3Dk8B2Y++E8hhx30af2WWXlldh74OZ859xriwi5EDNnzqB79//MRtTUdGfChMcLjKh4jkl9jkl9jknDHJfWL6X0CrBNA+3vAHs20J6AE5fnHFYeV2xHAFdRup9hWETUVQdPAc4GuqaU/t7I/mcDP1qqrTfw7yxhbFJEHFf3tFdaNG/5ov8c9vz6aAb+16848KQ/cPxhu7Lzdr0AOOv3t7Lx0B9z9R0TOeGw3T61z7DdtuKxya+0mSlrSVIr0NxT1p/9VT3NxuRxBRURHYH9gJtSSu8DjwP7AqSUZgL30sSLPlNKD2bH2qWR83w9u+fx9YjosfT2lNKfU0r9U0r9o8Mqn/2CltPMWXMBmPXeh9xy7zNs32fDT22/5vYnOHDPvp9qO3TfflzXhqasAbp1q2H69P+8gWHGjOnU1DT6Boaq55jU55jU55g0zHERmDyuyPYFugDPRsQ0YBdKlcg6i7NfU5auPk4FNqi72Tal9L/ZfY9zgfbNEPfnturKHem8aqcly3vttBnP/2smvTbouqTP8EFb89K0t5asr9F5ZXbp15tb73+mxeMtUv/tt2fq1JeZ9uqrLFiwgOuuuZphw/cvOqxCOSb1OSb1OSYNc1w+o2K+MJMb73lccR0BHJtSugqWPFH1akSsmlKqeF42pTQ2In4BrJ+tfxwRlwEXR8TxKaX5EdEe6JjDNXwm6669Otf85hsAdGjfnmvumMjdj07hql8fy8ZfWpfFixP/fuNdTj776iX77D94G8aN/ycfz19QVNiF6NChA6MvvJgRw/altraWkaOOZos+fYoOq1COSX2OSX2OScMcl8+oFUw1N6do6IlUtS4RsRiYWdb0B+B0Sg+1vF/W7wbgmpTSNRFxOTAmpfSPbNuG2fqW2St5Tk8pDc+27U/pkf3BKaX7s3snfwEcAnwAzANuA85PKS0z+2q36rqp06ZfaZ6LrhLvPXFx0SFIUlVbZaWY1MQLswvVbs0eqdPAU5v1mPPvPLXQa7byuAJIKTVUoz6ngX4Hly2PWmrbNGDLbPl+4P6ybbcAUba+kNLrfRp6xY8kSapYLl+YKZTJoyRJUp6qbNq6ulJhSZIk5crKoyRJUl6Cqpu2rq6rkSRJUq6sPEqSJOXGB2YkSZK0PHxgRpIkSW2VlUdJkqQ8Vdm0dXVdjSRJknJl5VGSJClPVXbPo8mjJElSXqL6nraurquRJElSrqw8SpIk5clpa0mSJFUqqix5dNpakiRJFbPyKEmSlJPAyqMkSZLaMCuPkiRJeYnsV0VMHiVJknITTltLkiSp7bLyKEmSlKNqqzyaPEqSJOWo2pJHp60lSZJUMSuPkiRJObLyKEmSpDbLyqMkSVJefM+jJEmSKhW+51GSJEltmZVHNZu+m2/Aw4/9rugwWpUvjvq/okNodV7642FFh9DqrLHKSkWHIClHVh4lSZLUZll5lCRJylG1VR5NHiVJknJUbcmj09aSJEmqmJVHSZKkvPieR0mSJC0Pp60lSZLUZll5lCRJyolfmJEkSVKbZuVRkiQpR9VWeTR5lCRJylN15Y5OW0uSJKlyVh4lSZLyEtU3bW3lUZIkSRWz8ihJkpSjaqs8mjxKkiTlqNqSR6etJUmSVDErj5IkSTmpxi/MmDxKkiTlqbpyR6etJUmSVDkrj5IkSXnxPY+SJElqy6w8SpIk5ajaKo8mj5IkSTmqtuTRaWtJkiRVzMqjJElSnqqr8GjyKEmSlCenrSVJktRmWXmUJEnKSUT1fZ7QyqMkSZIqZvKoqjJnzhyOPPxQtt1qc7bbegseH/9Y0SG1qHYRPPjL/bj6tEGfav/V1/oz/dLDlqx3X3tVbv3hXjz4y/145Jxh7L1NtxaOtGXNnz+ffQcNZPDAfuy2wzacd/bPAEgpcc7Pf8xO227BLv234i9/vLjgSIsz9q472brPpvTZrDfnn3du0eG0Co5JfccfezQbdFuXfn23LDqUFUpd9bG5fkVz2rqViogzgf8CaoHFwPHAr4DTgd8DnYC1gFWAGUB7oAcwDfhitt+s7HA7AO+mlDpHxIbAq8DJKaXfZee6GJiYUro8Wz8VOA5YmJ17HPD9lNLCHC+5WXz3tFPYe599ufLq61iwYAEff/xx0SG1qP8eshkvzpzL6qustKSt70Zr0WW1jp/qd/oBW3Hj46/x13Evs2m3Nbnuu4PZ+js3tXS4LaZTp07cMGYsq3XuzMKFCxmxzyD22HsIL7/0T2ZOn84jk56jXbt2zJr1dtGhFqK2tpZTTj6R2+64m5ru3dllwPYMH74/m2+xRdGhFcYxadjXRo7ihG+exLFHH1V0KCuU1pDwNScrj61QROwEDAe2SyltDewFvF63PaW0Y0qpL/AT4JqUUt+U0lYppS5Z+5+A0Vl735TSgqVO8Tbw7YjouFQ7EXECsA8wIKW0FbB91n+VHC61Wc2dO5dHHnqQkV8/BoCOHTvSpUuXgqNqOd3WWpV9+nbj7/dPXdLWLoJfHLEdP7n6qU/1TbAkwVxj1ZV44715LRlqi4sIVuvcGYCFCxeyaNFCIoLLL72E075/Ju3alf6vsGvXdYsMszBPTJhAr1692ahnTzp27Mihhx3OmFtvLjqsQjkmDdtl191Ya621ig5DBTN5bJ3WB2anlD4BSCnNTinNbMbjz6JUTRzZwLYzgf9OKc3Jzr0gpXRuSun9Zjx/LqZNe5V1unbl+G8czU47bMc3TziWjz76qOiwWsz/fLUfP7nqKRan/7Qdt88m3PHkdN6a8+nk8NwbnuErO2/E8xcdxHXfHcz3/vZEC0fb8mpra9lj5/706VXD7oP3pN/2O/Daq69w0w3Xsc/uAzji4BG8MvXlosMsxMyZM+jevceS9Zqa7syYMaPAiIrnmKhZRTP/KjllRPuIeCoixmTrG0XE4xExNSKuqSsgRUSnbH1qtn3Dpo5t8tg6jQV6RMRLEfGHiNg9h3P8Cjg9ItrXNUTEGkDnlNKrlR4kIo6LiIkRMXH27FlN75Cj2kWLmPzUk3zjuBN4bMKTrLrqalxwftu4T2nfvjXMen8+T097d0nbF7uswgE7fIlLxr5Yr/8hO23IVQ++Qp+Tb+TQ8+/jkv8eSJXNqtTTvn177n1kIpOnvMqTkyYy5YXn+GTBJ6y88sqMfWA8Xx11NKeceFzRYUpSc/k2MKVs/VeUZiV7A+8Bx2TtxwDvZe2js36NMnlshVJKHwL9KN13OAu4JiJGNfM5XgEep3RfZYMiYt+ImBwR0yJi4DKO8+eUUv+UUv911unanCEut2413anp3p3td9gRgIMOPoTJTz3VxF7VYcdNujJ0u+48M/pALjtxF3bb4ouM/9Vweq63Ok9dcADPjD6QVTt24MkLDgDgq7v34sbHXwPgiamzWXml9qy9eqciL6HFrNmlC7vsujv33TOWbt1q2G/EgQDsN+JAXnj+2YKjK0a3bjVMn77kzhhmzJhOTU1NgREVzzFRc2rpB2YiojswDLg0Ww9gD+AfWZcrgAOz5QOydbLte0YTJzF5bKVSSrUppftTSj8FTgK+nMNpzgG+T1YEz6amP4yIjbL1u7J7KJ8D6t0f2dp88YtfpHv3Hrz0YqnSdv9949hs880Ljqpl/PzayfQ5+Ua2/s5NHPP7h3nwhTfZ8Pjr2PSk69n6Ozex9Xdu4uMFi9jutNI9W9Pf+Yjd+3wRgE26rUGnldoz+/1PiryEXM2ePYu5c+YAMG/ePB64bxy9N96UIcP355GHHgDg0YcfpFevjYsMszD9t9+eqVNfZtqrr7JgwQKuu+Zqhg3fv+iwCuWYqNlELsnjOnWzftlv6WmT3wLfo/TQK8DawJyU0qJsfTpQ97ehGrLnKrLtc7P+y+TT1q1QRGwKLE4p1d2A1Rd4DWjWdyOklP4ZES8AI4C6m97+B/hjRByeUpqT/e1j5eY8b55+Pfoijh71VRYsWMBGG/XkT3/5a9EhtUo/uvJJLjx2R745ZHMSiW9eUt2vNHrrzTc4+YRjqK2tZfHixRxw0CHsM3QYO+60M988diSX/P5CVlutM7+5+E9Fh1qIDh06MPrCixkxbF9qa2sZOepotujTp+iwCuWYNOyorx7BQw/cz+zZs+m1YXd+/JOfMeroY5reUc1tdkqpf0MbImI48HZKaVJEDMrj5CaPrVNn4HcR0QVYBEylNIX9j0b3+mzOBsrndv8IrAY8HhGfAB8CjyzVp9XaZpu+PPxY9T/80ZiHp7zFw1Peqtfe/dhrliy/OHMuQ34+tiXDKlSfLbdm3MP1/7lYs0sXrvyHT9ACDBm6H0OG7ld0GK2KY1Lf3/7vqqJDWOEEtPQ95TsD+0fEfpSKP2sAFwJdIqJDVl3sTuk1f2R/9gCmR0QHYE3gncZOYPLYCqWUJgEN3WM4aKl+lwOXN7D/WQ20dc7+nEZZBTOl9DRlty+klBJwfvaTJEmfS8u+2Dul9APgBwBZ5fH0lNKREXEdcAhwNaW3rdT9zfmWbP2xbPu9WS6wTN7zKEmSVP2+D5waEVMp3dN4WdZ+GbB21n4qcEZTB7LyKEmSlKOiXoWWUrofuD9bfoXSF+eW7jMfOHR5jmvlUZIkSRWz8ihJkpSjavu2tcmjJElSXqK4aeu8OG0tSZKkill5lCRJykkA7dpVV+nRyqMkSZIqZuVRkiQpR9V2z6PJoyRJUo6q7Wlrp60lSZJUMSuPkiRJeanCV/WYPEqSJOUkcNpakiRJbZiVR0mSpNyElUdJkiS1XVYeJUmSclRlhUeTR0mSpDw5bS1JkqQ2y8qjJElSXqrwPY9WHiVJklQxK4+SJEk5qcaXhJs8SpIk5ajKckenrSVJklQ5K4+SJEk5ctpakiRJFauy3NFpa0mSJFXOyqMkSVJewmlrqVFV9r+Pz+2lPx5WdAitzpe+fGHRIbQ6791+etEhSFLFTB4lSZJyUnrPY9FRNC+TR0mSpNxE1U1b+8CMJEmSKmblUZIkKUdVVng0eZQkScqT09aSJElqs6w8SpIk5SWqb9rayqMkSZIqZuVRkiQpJ6X3PFZX6dHkUZIkKUfVljw6bS1JkqSKWXmUJEnKUZUVHq08SpIkqXJWHiVJknJUbfc8mjxKkiTlxfc8SpIkqS2z8ihJkpSTIJy2liRJUuWqLHd02lqSJEmVs/IoSZKUo3ZVVnq08ihJkqSKWXmUJEnKUZUVHk0eJUmS8hJRfS8Jd9pakiRJFbPyKEmSlKN21VV4tPIoSZKkyll5lCRJylG13fNo8ihJkpSjKssdnbaWJElS5aw8SpIk5SSAoLpKj1YeVTXmz5/PrgN3ZMd+fem3zZb84mc/LTqkQsyfP599Bw1k8MB+7LbDNpx39s8ASClxzs9/zE7bbsEu/bfiL3+8uOBIW0a7dsFjf/ga1//8IAB279uDR3//NSb+eRR/+e5Q2mePQR6+x+ZM+NNInrhkJPeNPoKtenYtMuwWd/yxR7NBt3Xp13fLokNpNcbedSdb99mUPpv15vzzzi06nFbDcVl+7aJ5f0UzeWwhEXFmRDwfEc9ExOSIuC/7c2pEzM2WJ0fEwKz/5Ii4eqljXB4RMyKiU7a+TkRMy5Y3jIh5EfFUREyJiAkRMaps31ERcXG2fFZEfBwR65Zt/7Bseb2I+H8R8UpETIqIxyLioDzHpzl06tSJO8aO4/FJkxk/8SnuHnsXEx4fX3RYLa5Tp07cMGYs9z06iXGPTOTee8YyccLjXH3l35g5fTqPTHqOhyc+y4GHfKXoUFvESQdtx4v/fhco3Xd06XeHctQ5Y+h/3OX8+633+eo+fQCY9uZc9jn9arY//gr+5/+N5/en7FNk2C3uayNHcfOYO4sOo9Wora3llJNP5OZb7+CpZ17guquvYsoLLxQdVuEcF4HJY4uIiJ2A4cB2KaWtgb2AI1NKfYFjgYdSSn2z36MRsTnQHtg1IlZb6nC1wNHLONW/UkrbppQ2Bw4HTomIry+j72zgtAZiDeAm4MGUUs+UUr/sWN2X66ILEBF07twZgIULF7Jw4cLqu0u5AhHBamXjsGjRQiKCyy+9hNO+fybt2pX+Z9+167qNHaYq1KzTmSE79OR/73wGgLXXWIUFCxczdcZ7ANz75DQO3GUTAMa/MJM5H34CwIQpM6lZp3MxQRdkl113Y6211io6jFbjiQkT6NWrNxv17EnHjh059LDDGXPrzUWHVTjH5TOIIJr5VzSTx5axPjA7pfQJQEppdkppZiP9jwD+DowFDlhq22+B70REo/erppReAU4FTl5Gl78Ch0XE0v+22ANYkFL6U9mxXksp/a6x87UWtbW17Nh/W75Usx577rkXO+ywY9EhFaK2tpY9du5Pn1417D54T/ptvwOvvfoKN91wHfvsPoAjDh7BK1NfLjrM3J3/33tw5qUPsnhxaX323Hl0aN+O7TZeD4CDdt2E7l1Xr7ffqCFbcdcTr7ZkqGplZs6cQffuPZas19R0Z8aMGQVG1Do4LgKTx5YyFugRES9FxB8iYvcm+h8GXA1cRSmRLPdv4GHgaxWc90lgs2Vs+5BSAvntpdr7ZPtVJCKOi4iJETFx9uxZle6Wm/bt2/P4xKd4+dXXmTjxCZ5/7rmiQypE+/btufeRiUye8ipPTprIlBee45MFn7Dyyisz9oHxfHXU0Zxy4nFFh5mroTv25O05H/PUy299qv2oc27lvBMG89BFR/LBvAXULk6f2r7bNj0YOWQrfnTpgy0ZrqQqVvq+dfP9imby2AJSSh8C/YDjgFnANeX3I5aLiP6UqpT/BsYB2zZQHfwf4Ls0/d9fU/+IXQSMjIj6pZf/xPP7iHg6Ip5oaHtK6c8ppf4ppf7rrNN6HjDo0qULu+0+iLvHtu17uNbs0oVddt2d++4ZS7duNew34kAA9htxIC88/2zB0eVrpz41DB/Qi3/+7Rv87YfDGdR3A/76/f14fMob7HXa1ex68pU8/Ox0pk5/b8k+W260Dn/8zr4c+tObePeD+QVGr6J161bD9OmvL1mfMWM6NTU1BUbUOjguyy+AdhHN+iuayWMLSSnVppTuTyn9FDgJ+PIyuh4BbJY9CPMvYI2l+6aUXgYmA0098bAtMKWRmOYA/w84saz5eWC7sj4nAnsCrSczXIZZs2YxZ84cAObNm8e94+5hk02XVXitXrNnz2Ju2Tg8cN84em+8KUOG788jDz0AwKMPP0ivXhsXGWbufvLXh+h95CVsdtRfOOqcMdw/+d8c/avb6dplVQA6rtSe076yA3+5bTIAPbquztU/OYBjzrt9yT2Rarv6b789U6e+zLRXX2XBggVcd83VDBu+f9FhFc5xEfiexxYREZsCi7OkD6Av8FoD/dpRSgi3qrsnMiIGAz8G/rJU97OB2xo554bAr4Gm7lX8DfAE//ln4V7gnIj475TSH7O2VZs4Rqvw5htv8I1jRrG4tpbFixdz8CGHst+w4UWH1eLeevMNTj7hGGqzcTjgoEPYZ+gwdtxpZ7557Egu+f2FrLZaZ35z8Z+aPlgV+s6h2zN0x560i+AvYybzwORSFeUHX92JtdZYhd9+ay8AFtUuZpeT/q/IUFvUUV89goceuJ/Zs2fTa8Pu/PgnP2PU0ccUHVZhOnTowOgLL2bEsH2pra1l5Kij2aJPn6LDKpzj8tm0gmJhs4qUUtO99LlERD9KSVwXYBEwFTgupTQ7IgYBp6eUhmf3Qv4qpTSgbN/2wAxKVcT/AcaklP6RbbuB0hPcG2bJ4hTgn8DKwAfAH1JKl2d9RwH9U0onRcRZwIcppV9n234DfCelFNn6+sBoYEdK0+wfAX9KKV3T2HVu169/emR8g7PbbdYH8xcVHUKr86UvX1h0CK3Oe7efXnQI0gprlZViUkqpf9FxLMsXNtwi7fGTvzfrMW84pn+h12zlsQWklCYBA5ex7X7g/mz5AWDAUttrgS9mq6OW2nZw2fI0YJVGYrgcuDxbPmupbadSejK7bv0NSq/nkSRJn1NreL1OczJ5lCRJyklreUK6OfnAjCRJUpWIiJWzr8w9nX3Z7mdZ+0YR8Xj2ZbtrIqJj1t4pW5+abd+wqXOYPEqSJOWohV/V8wmwR0ppG0oP6A6JiAHAr4DRKaXewHtA3RNxxwDvZe2js36NX89nHAdJkiRVIJr515hU8mG2ulL2S5S+IPePrP0K4MBs+YBsnWz7ntHETZomj5IkSSuWdeq+7pb9PvXJsIhoHxGTgbeBuym9N3pOSqnuFSDTgbq3u9cArwNk2+cCazd2ch+YkSRJylEOT1vPbuxVPdmbWvpGRBfgRpb9qeLPxMqjJElSFcq+JHcfsBPQJSLqiobdKb1DmuzPHgDZ9jWBdxo77jIrjxHxO0pz5MsK6ORKg5ckSWqLSt+2bsHzRXQFFqaU5kTEKsDelB6CuQ84BLgaGAncnO1yS7b+WLb93tTEF2Qam7ae+PnClyRJauMiWvol4esDV2RfqGsHXJtSGhMRLwBXR8QvgaeAy7L+lwF/j4ipwLtU8JGQZSaPKaUrytcjYtWU0sef7TokSZKUt5TSM5Q+abx0+yvADg20zwcOXZ5zNHnPY0TslGWr/8zWt4mIPyzPSSRJktqquq/MNNevaJU8MPNbYF+ymydTSk8Du+UZlCRJUrWIbOq6uX5Fq+hp65TS60s11eYQiyRJklq5St7z+HpEDARSRKwEfBuYkm9YkiRJK76Wftq6JVRSeTwBOJHSG8hnUvpO4ol5BiVJkqTWqcnKY0ppNnBkC8QiSZJUdVrDfYrNqZKnrXtGxK0RMSsi3o6ImyOiZ0sEJ0mStKKLZv4VrZJp6/8HXEvppZPdgOuAq/IMSpIkSa1TJcnjqimlv6eUFmW//wNWzjswSZKkFV0EtIto1l/RGvu29VrZ4h0RcQalbyEm4DDg9haITZIkSa1MYw/MTKKULNaluMeXbUvAD/IKSpIkqVq0gmJhs2rs29YbtWQgkiRJ1ajanrau5CXhRMSWwBaU3euYUvpbXkFJkiSpdWoyeYyInwKDKCWPtwNDgYcBk0dJkqQmVFnhsaLK4yHANsBTKaWvR8R6wP/lG5YkSdKKL2gdT0g3p0pe1TMvpbQYWBQRawBvAz3yDUuSJEmtUSWVx4kR0QX4C6UnsD8EHss1KkmSpGoQbXDaOqX0zWzxTxFxJ7BGSumZfMOSJElSa9TYS8K3a2xbSunJfELSiiqovtcRfF5rrLJS0SG0Ou/dfnrRIbQ6vb51Y9EhtDovX3hg0SG0Sm/OnV90CPoMqu3fjY1VHi9oZFsC9mjmWCRJkqpOJQ+YrEgae/yUshAAACAASURBVEn44JYMRJIkSa1fRS8JlyRJ0vKrxlu6qq2SKkmSpBxZeZQkScpRu+oqPFb0ecIAjgR6ppR+HhEbAF9MKU3IPTpJkqQVXLUlj5VMW/8B2Ak4Ilv/APh9bhFJkiSp1apk2nrHlNJ2EfEUQErpvYjomHNckiRJK7yI6ntgppLkcWFEtKf0bkcioiuwONeoJEmSqkRbnLa+CLgRWDcizgYeBs7JNSpJkiS1SpV82/rKiJgE7EnpdUUHppSm5B6ZJElSFaiyWeuKnrbeAPgYuLW8LaX07zwDkyRJUutTyT2Pt1G63zGAlYGNgBeBPjnGJUmStMILoF2VlR4rmbbeqnw9IrYDvplbRJIkSVWk2j7nt9zXk1J6Etgxh1gkSZLUylVyz+OpZavtgO2AmblFJEmSVEWqbNa6onseVy9bXkTpHsjr8wlHkiSpekRE27rnMXs5+OoppdNbKB5JkiS1YstMHiOiQ0ppUUTs3JIBSZIkVZMqKzw2WnmcQOn+xskRcQtwHfBR3caU0g05xyZJkqRWppJ7HlcG3gH24D/ve0yAyaMkSVITqu3b1o0lj+tmT1o/x3+Sxjop16gkSZKqQFt7SXh7oDOfThrrmDxKkiS1QY0lj2+klH7eYpFIkiRVoSorPDb6hZkqu1RJkiR9Xo1VHvdssSgkSZKqUbShB2ZSSu+2ZCCSJEnVKKpsMrexaWtJkiTpUyp5z6MkSZI+g9KreoqOonmZPEqSJOWo2pJHp61VVcbedSdb99mUPpv15vzzzi06nFbBMamvrY9Ju4C7fjiYK765EwC/+3p/HjxrL8b9eE8u+Np2dMj+Tddrvc7c8t3deeWi/Tl+r95FhlyYzTfZiO2325oB22/LLjttX3Q4hXhl6ksMH7zjkt82Pdfjfy+5mDnvvctRhwxnjx234qhDhjN3zntFh6oWYvJYkIgYHRGnlK3fFRGXlq1fEBGnRkSHiJgVEecutf/9EdF/qbZBETGmbP2XEXFnRHQq7x8R0yLi+rJ+h0TE5WXrQyJiQkT8MyImR8Q1EbFBsw5ADmpraznl5BO5+dY7eOqZF7ju6quY8sILRYdVKMekPscEjt2jNy+/+cGS9RsnvM5uZ93Dnr8Yx8orteO/dtkQgDkfL+DH1z7NJfdMLSjS1uGOsfcy/omnePixJ4oOpRA9e2/CmPseZ8x9j3PzPY+y8iqrsM9++/Oniy5g4G6DuPfxZxm42yD+dNEFRYfaakVEs/6KZvJYnEeAgQAR0Q5YB+hTtn0g8CiwN/AScGgsxz8xEfEjYGfgoJTSJw106RcRWzSw35bA74CRKaXNUkp9gSuBDSs9d1GemDCBXr16s1HPnnTs2JFDDzucMbfeXHRYhXJM6mvrY7J+l5XZc8v1uOqRaUva7n3+rSXLk6e9x/pdVgHgnQ8W8PRrc1hYu7ilw1Qr9eiD97HBhj2p6bEB99w5hoMPOxKAgw87krvvuLXg6NRSTB6L8yiwU7bch9I3xD+IiC9ERCdgc+BJ4AjgQuDfZf0bFRGnAUOBESmlecvodgFwZgPt3wfOSSlNqWtIKd2SUnqwknMXaebMGXTv3mPJek1Nd2bMmFFgRMVzTOpr62Pys0O35pc3Ps/iBvLBDu2CL++4Afe98Fb9jW1UEOw/bF92HtCfv17656LDKdyYm65jxMGHAjB71tusu976AHRd94vMnvV2kaG1WnUPzDTnr2g+MFOQlNLMiFiUTQcPBB4DaigliHOBZykl93sBxwNdKCWSjzZx6J2BTYF+KaUPG+l3LfDNiFj6RqY+wK8rvY6IOA44DqDHBq1+Zltq0/ba8ovM/uATnv33HHbaeJ162885oi+PT53NhKnvFBBd63TPfQ/RraaGt99+mxH77cMmm27GLrvuVnRYhViwYAHj7rqd755Z/8vFrWU6tVWKtvV5QuXvUUqJY13y+FjZ+iPAcOC+rHp4PXBgRLRv4phTKf1FZ+8m+tUC5wM/WFaHiFg7u+fxpYg4vaE+KaU/p5T6p5T6d12naxOnzFe3bjVMn/76kvUZM6ZTU1NTYETFc0zqa8tj0r/XWuyz9fqM/+U+/OGY7dl503W4aFQ/AL4zbDPW7tyRs/7xbMFRti7dsn821l13XfY/4EAmPjGh4IiK88C4u+izVV/WWXc9ANbpui5vv/UGAG+/9QZrF/zvALUck8di1d33uBWlaevxlCqPdfc7HgHsFRHTgEnA2sAeTRzzLWA/4LcRMbiJvn8HdgN6lLU9D2wHkFJ6J7vn8c9A54qvqiD9t9+eqVNfZtqrr7JgwQKuu+Zqhg3fv+iwCuWY1NeWx+Tcm1+g/w/vZMCPxvLNy57gkRdnc/Llkzhi5y8xaPN1OfGvT5BS0VG2Hh999BEffPDBkuVx99zNFn22LDiq4tx643+mrAH23HcYN1xzJQA3XHMlew0ZXlRorV67iGb9Fc1p62I9CpwOvJJSqgXejYgulKaOvw1cCvSoe+AlIr5OKaG8u7GDppReioiDgZsiYlhKafIy+i2MiNHAGcC9WfN5wI0RMb7svsdVP9dVtpAOHTow+sKLGTFsX2praxk56mi26NOn6R2rmGNSn2NS37lH9GX6ux9zy3d3B+D2yTP57e0v0nWNTtxxxmA6r9yBxSnxjT16M+jn9/Dh/EUFR9wy3n7rLQ7/ysEA1C5axFcOP4J99h1ScFTF+Pijj3jkgXs5+9e/W9J2wsmn8a1vfI1rr7yCmu4b8LtL/15ghGpJkfxrZmGyKej3gItSSj/K2i6nVH08BxiaUjq8rP9awItAd+AuSg/VLMw2Pwb8Hjg9pTQ8678PpQR0MHBZtm1iVsnsn1KanT2c8yowNqU0KttvGHAWsAYwm9LDOj9NKb3U2PX069c/PfL4xM8xIlLb1OtbNxYdQqvz8oUHFh1Cq/Tm3PlFh9Dq9Fp31Ukppf5N9yzGBpttlU6/9JZmPea3d+1Z6DVbeSxQVm1cY6m2UWWrVyy17V2g7qaSQcs47P1l/ccCdU+xDCpr37Bs+ROg21LnuQ24ran4JUlS01rBTHOz8p5HSZIkVczKoyRJUm6CdlRX6dHkUZIkKSeB09aSJElqw6w8SpIk5aWVfFKwOVl5lCRJUsWsPEqSJOWoNXwVpjmZPEqSJOXEB2YkSZLUppk8SpIk5ahdRLP+GhMRPSLivoh4ISKej4hvZ+1rRcTdEfFy9ucXsvaIiIsiYmpEPBMR2zV5Pc0yKpIkSWoNFgGnpZS2AAYAJ0bEFsAZwLiU0sbAuGwdYCiwcfY7DvhjUycweZQkScpRRPP+GpNSeiOl9GS2/AEwBagBDgCuyLpdARyYLR8A/C2VjAe6RMT6jZ3DB2YkSZJyEhRXqYuIDYFtgceB9VJKb2Sb3gTWy5ZrgNfLdpuetb3BMpg8SpIkrVjWiYiJZet/Tin9ubxDRHQGrgdOSSm9H2Uly5RSioj0WU9u8ihJkpSXgGhqrnn5zU4p9V/mKSNWopQ4XplSuiFrfisi1k8pvZFNS7+dtc8AepTt3j1rWybveZQkScpRNPOv0XOVMtXLgCkppd+UbboFGJktjwRuLms/KnvqegAwt2x6u0FWHiVJkqrHzsDXgGcjYnLW9kPgXODaiDgGeA34SrbtdmA/YCrwMfD1pk5g8ihJkpSToGU/T5hSephlFyj3bKB/Ak5cnnM4bS1JkqSKWXmUJEnKUZV92trkUZIkKU8tOGvdIpy2liRJUsWsPEqSJOUm8njPY6FMHiVJknJS5OcJ81Jt1yNJkqQcWXmUJEnKUbVNW1t5lCRJUsWsPEqSJOWouuqOJo+SJEn5ieqbtjZ5lKSC/et3BxUdQqvT76djiw6hVbrvjMFFhyCZPEqSJOXFV/VIkiSpTbPyKEmSlCPveZQkSVLFqit1dNpakiRJy8HKoyRJUo6qbNba5FGSJCkvpaetqyt7dNpakiRJFbPyKEmSlKNqm7a28ihJkqSKWXmUJEnKTRBVds+jyaMkSVKOnLaWJElSm2XlUZIkKSe+qkeSJEltmpVHSZKkvET13fNo8ihJkpSjaksenbaWJElSxaw8SpIk5cj3PEqSJKkiAbSrrtzRaWtJkiRVzsqjJElSjqpt2trKoyRJkipm5VGSJClH1faqHpNHSZKkHDltLUmSpDbLyqMkSVJOqvFVPSaPkiRJuQmnrSVJktR2mTyqqoy960627rMpfTbrzfnnnVt0OK2CY1KfY1JfWx2Tjh3acfV/78gNJ+3EzScP5MQ9ewGwY8+1uO7EAVx/0gD+/o3t2WCtVQD4yg7dufFbOy1p79V1tSLDz938+fPZd9BABg/sx247bMN5Z/8MgP33HcweO/dnj537s/UmX2LkEV8uONJWLEpPWzfnr2hOW6tq1NbWcsrJJ3LbHXdT0707uwzYnuHD92fzLbYoOrTCOCb1OSb1teUxWbBoMUdfNpGPF9TSoV3w9+N24KGXZvOTAzbnW/83mVdmfcThO/bg+ME9OfP657nt6Te4dsJ0AAZv1pXv7bcpx1/xZMFXkZ9OnTpxw5ixrNa5MwsXLmTEPoPYY+8h3HLXfUv6HP3VrzBkvxEFRqmWllvlMSJGR8QpZet3RcSlZesXRMSpEdEhImZFxLlL7X9/RPRfqm1QRIwpW/9lRNwZEZ3K+0fEtIi4vqzfIRFxedn6kIiYEBH/jIjJEXFNRGzQyLVcHhGvRsTTEfFSRPwtIrqXbV8za5saEf/KltfMtt0YEQeW9X0xIn5Utn59RBycXVuKiBFl28ZExKBseXhEPJXF8EJEHB8RZ2bxT46I2rLlk7N9fhsRMyKiXdkxR0XExdnyWdn2ydkxjyjrNyAiHs+2TYmIs5Y1Pq3FExMm0KtXbzbq2ZOOHTty6GGHM+bWm4sOq1COSX2OSX1tfUw+XlALQIf2QYf2QUqQEqzWqVRf6dypA2+//wkAH31Su2S/VTq2J7V8uC0qIlitc2cAFi5cyKJFC4my0tcH77/Pww/ez9DhBxQV4gohmvlXtDynrR8BBgJkycs6QJ+y7QOBR4G9gZeAQyMqL8ZmCdjOwEEppU8a6NIvIur9tTkitgR+B4xMKW2WUuoLXAls2MQpv5tS2gbYFHgKuDciOmbbLgNeSSn1Tin1Al4F6hLl8nFYG/gI2KnsuDtRGgeA6cCZDcS8EvBnYEQWw7bA/Smls1NKfbNrmFe3nFK6KBvzg4DXgd0bua7R2f4HAJdk5wK4Ajgu27YlcG0T41O4mTNn0L17jyXrNTXdmTFjRoERFc8xqc8xqa+tj0m7gOtPGsBDPxjEY1Pf4dnpc/nJjc/zp5HbMu57u7H/tutz6YOvLul/xI49uOPUXTh13004Z8w/C4y8ZdTW1rLHzv3p06uG3QfvSb/td1iy7Y4xN7Pr7oNZfY01CoywdSs9bR3N+itansnjo/wnSeoDPAd8EBFfiIhOwObAk8ARwIXAv/l0UrVMEXEaMJRSMjVvGd0uoIFEDPg+cE5KaUpdQ0rplpTSg5WcO5WMBt4EhkZEb6Af8Iuybj8H+kdEL0rjMDBrHwjcCnSNko0oJX1vZtufBuZGxN5LnXZ1SrcYvJPF8ElK6cUmQh0EPA/8kdIYN3VdLwMfA1/ImtYF3si21aaUXmhov4g4LiImRsTEWbNnNXUaSWp1Fif48sXj2eO8B9mq+5r0XrczR+38JU644in2PO9Bbpw0k+/tt+mS/lc9/jpDf/Mwo+96iRMG9Sww8pbRvn177n1kIpOnvMqTkyYy5YXnlmy78R/XctAhhxUYnYqQW/KYUpoJLMqmgwcCjwGPU0oQ+wPPZuffi1JCdRUVJDmUqo0nAENTSh820u9aYLssuSvXh1LS+nk9CWwGbAFMTiktmcvIlidn55oEbJlVKevG4UVKyXNd9bXc2cCPyhtSSu8CtwCvRcRVEXFk+VT0MhxBaUxvBIaVVRQbFBHbAS+nlN7OmkYDL2bT7sdHxMoN7ZdS+nNKqX9KqX/Xdbo2EVK+unWrYfr015esz5gxnZqamgIjKp5jUp9jUp9jUvLB/EVMeOVddt1kHTb94uo8O30uAHc++ybbbtClXv/bn32TPbYo9v/3WtKaXbqwy667c989YwF4553ZPDXpCfbad7+CI2v9nLZePnVVt7qk6bGy9UeA4cB9WfXweuDAiGjfxDGnUhq7patzS6sFzgd+sKwOEbF2dk/fSxFxegXX86ndK+mUTak/D2wHDKCUQC89DuX9H8xi22Wp9mOBPYEJwOnAX5cZWClR3Q+4KaX0fnbOfZfR/TsR8XzW5+yy8/2cUpI/Fvgv4M5KrrdI/bffnqlTX2baq6+yYMECrrvmaoYN37/osArlmNTnmNTXlsfkC6uuxOorl+5t7NShHTv1XptXZn3I6it34EtrrwpQanv7IwA2yNoAdt+0K6+983HLB92CZs+exdw5cwCYN28eD9w3jt4bl6qwY266gb2H7MfKKzdYW1AVy/tp67r7/baiNG39OnAa8D7wv8BIYJeImJb1XxvYA7i7kWO+BRwJjIuId1NK9zXS9++UksfnytrqErmnU0rvAH2zxLHz8l0a2wLjgBeyY7RLKS2GJfd49s22QWkcdgNWTym9FxHjgZOyY1zSwLHrqo+LyhtTSs8Cz0bE3yndVzlqGbHtC3TJ+gKsCswDxjTQd3RK6dcRsT9wWUT0SinNz873L+CPEfEXYFZErJ2NWavUoUMHRl94MSOG7UttbS0jRx3NFn36NL1jFXNM6nNM6mvLY9J19U6cc8iWtGtXupfsrmff5IEXZ/PTm17gt/+1DSnB3HkL+fENzwPwXwN6sFOvtVm0eDHvz1vED//xXBNnWLG99eYbnHzCMdTW1rJ48WIOOOgQ9hk6DICbrr+Wb33nuwVHuIJoDeXCZpR38vgopSrZK9lU7rsR0YXSdO63KT1U0qPugZeI+Dql6dbGkkdSSi9FxMHATRExLKU0eRn9FkbEaOAM4N6s+TzgxogYX3bf46oN7d+Q7KGebwHrA3emlBZExFOUkr2fZ91+BDyZUppaNg4XAPdn689QqkKux6cT27q4x0bEL7JzEBGdgf4ppbr9+wKvNRLmEcCxKaWrsv1XA16NiGVeZ0rplog4hlJCf0lEDANuTyklYGNKldw5jZyzVRgydD+GDHUKpZxjUp9jUl9bHZOX3vqQQ34/vl77uBfeZtwLb9drP/e2pm43ry59ttyacQ8/0eC2G2+/p4WjWXH5hZnl8yylp6zHL9U2FxgM3LvUk9I3AyOyB2oAbouI6dnvuvIDp5SeAL4O3JI9mLIsl1GWJGfVu28Df8tem/MIpfsP/18T13J+RDxN6cnw7YHBKaUF2bZjgE2y1/T8C9gka6vzKNCT0nQ1KaVFwNvAxLpqZQPOBuoefwzge1m8k4GfsYyqY5YgDgFuK7vmj4CHgaZexPVz4NSscvo1Svc8TqZUwT2y/L5OSZLUNkWpsCR9fv369U+PPD6x6DAkVYF+Px1bdAit0n1nDC46hFZnvTU6Tkop9W+6ZzE232rbdMXN9zfrMXfs1aXQa/YLM5IkSTmqrklrk8dPiYjfU3oVULkLU0r/W0Q8kiRJrY3JY5mU0olFxyBJkqpMlZUe835gRpIkSVXEyqMkSVJOSl+Fqa7So8mjJElSXgKiunJHp60lSZJUOSuPkiRJOaqywqOVR0mSJFXOyqMkSVKeqqz0aPIoSZKUm6i6p62dtpYkSVLFrDxKkiTlqNpe1WPyKEmSlJOg6m55dNpakiRJlbPyKEmSlKcqKz1aeZQkSVLFTB4lSZJyFM38nybPF/HXiHg7Ip4ra1srIu6OiJezP7+QtUdEXBQRUyPimYjYrqnjmzxKkiTlKKJ5fxW4HBiyVNsZwLiU0sbAuGwdYCiwcfY7DvhjUwc3eZQkSaoiKaUHgXeXaj4AuCJbvgI4sKz9b6lkPNAlItZv7Pg+MCNJkpSjHJ6XWSciJpat/zml9Ocm9lkvpfRGtvwmsF62XAO8XtZvetb2Bstg8ihJkrRimZ1S6v9Zd04ppYhIn3V/p60lSZLyEjn8Ppu36qajsz/fztpnAD3K+nXP2pbJ5FGSJClHLf209TLcAozMlkcCN5e1H5U9dT0AmFs2vd0gp60lSZKqSERcBQyidG/kdOCnwLnAtRFxDPAa8JWs++3AfsBU4GPg600d3+RRkiQpJ0HFr9dpNimlI5axac8G+ibgxOU5vsmjJElSjqrs64Te8yhJkqTKWXmUJLU6k362T9EhtEpfOPQvRYegz6LKSo9WHiVJklQxK4+SJEk5+hyv12mVTB4lSZJy1NJPW+fNaWtJkiRVzMqjJElSjqqs8GjyKEmSlKsqyx6dtpYkSVLFrDxKkiTlJKi+p62tPEqSJKliVh4lSZLyEtX3qh6TR0mSpBxVWe7otLUkSZIqZ+VRkiQpT1VWerTyKEmSpIpZeZQkScpNVN2rekweJUmSclRtT1s7bS1JkqSKWXmUJEnKSVB1z8uYPEqSJOWqyrJHp60lSZJUMSuPkiRJOaq2p62tPEqSJKliVh4lSZJyVG2v6jF5lCRJylGV5Y5OW0uSJKlyVh4lSZLyEtU3bW3lUZIkSRWz8ihJkpSr6io9mjxKkiTlJHDaWmrVxt51J1v32ZQ+m/Xm/PPOLTqcVsExqc8xqc8xqa+tj0m7dsFjFxzE9WfuC8A9Z49g/G8OZvxvDuaVy/6La8/YG4BNatbk/nP3Z861R3PKAVsVGbJaiJVHVY3a2lpOOflEbrvjbmq6d2eXAdszfPj+bL7FFkWHVhjHpD7HpD7HpD7HBE4aviUvTp/D6qt2BGCvM29dsu2q7+3FrRNeA+C9Dz/htEsfZcSOGxYR5gqhygqPK0blMSJGR8QpZet3RcSlZesXRMSpEdEhImZFxLlL7X9/RPRfqm1QRIwpW/9lRNwZEZ3K+0fEtIi4vqzfIRFxedn6kIiYEBH/jIjJEXFNRGzQyLV8KpaI2DAiniuLaW52nCkR8dOsfdWIuDIino2I5yLi4Yj4UtZvckS8GREzytY7RsQ6EbEwIk5Y6vzTImKdbLk26/9cRNwaEV2y9nYRcVHW/mxEPBERGzXxX1PhnpgwgV69erNRz5507NiRQw87nDG33lx0WIVyTOpzTOpzTOpr62NSs/ZqDOnXg/+958V621ZfZSV236obtz4+DYBZc+czaepsFi5a3MJRrjgimvdXtBUieQQeAQZCKbEB1gH6lG0fCDwK7A28BBwaUfnwRsSPgJ2Bg1JKnzTQpV9E1PvrZkRsCfwOGJlS2iyl1Be4Etiw0nM34KHsOP2Br0bEdsC3gbdSSlullLYEjgHeTCn1zfr+CRhdt55SWgAcCowHjmjkXPOy/lsC7wInZu2HAd2ArVNKWwEHAXM+xzW1iJkzZ9C9e48l6zU13ZkxY0aBERXPManPManPMamvrY/J+UcP4MwrJrB4caq3bcSOG3L/MzP4YN7CAiJTa7CiJI+PAjtly32A54APIuILEdEJ2Bx4klKidCHw77L+jYqI04ChwIiU0rxldLsAOLOB9u8D56SUptQ1pJRuSSk9WMm5G5NS+giYBPQG1gdmlG17cRlJbrkjgNOAmojoXsEpHwNqsuX1gTdSSouz801PKb23nJcgSVoBDe2/AW/Pnc9Tr8xucPtXdu3FtQ/9q4WjWrFFM/+naCtE8phSmgksyqaDB1JKdB6nlCD2B56ldC17AbcCV9F4xa3OzsAJwNCU/n97dx5nZ12fffxzEbawryKylN0QEBPAlqVQSFQWASnKg2AfURGxjwLF2lotgtiKPgUELdaKIm4FFGW1Iij7LiEsSUAhBUQ2RTYjIEu4+sfvHuYwWyZtcn5n5r7evs7Lc9/3mTnXuV9h5ju/1X8Y4XXfB7aWtMmA81tQitZFTtLqwHbAHOAbwMcl3dB0r2+6gK9dD1jb9s8p2Q9YwOsnANOBC5tT3wf2brq0T5I0dYSv/aCkGZJmPPa7x0b9+RaH171uHR588NevHD/00IOss846I3zF+Jd7MljuyWC5J4O1+Z5sP2kt9nrT+vziq+/i2387jV3e8Dq+8Te7ALD6isuw7aZrcvEtvx75m8S4NiaKx8b1lMKxr3i8oeP4OmAv4Iqm9fCHwL5NUTSSuZRxrG9ZwOvmAycAnxjuBZJWb4qtuyV9bITvNbgP4NXndpJ0K3Ap8Hnbc2zfBmzUZFgNuFnS5iO8xwGUAhDgbIYvpCdKug14FFgL+CmUlkbg9ZTP+zJwmaTpQ34Y+zTb29reds011hwh0uK37ZvexNy593D/fffxwgsvcM73zuZte+1TNVNtuSeD5Z4MlnsyWJvvyTHfvZlNDj2LSYedzXtOupwrZz3M+0+5EoC/3GEjLp7xAM+/OL9uyLFGi/hR2Viabd037vENlG7rX1O6ZX8PnAEcDPy5pPub168OTKMpiIbxG+DdlOLoCdtXjPDa71CKqdkd5+YAWwO3234cmNIUjiuM8H0eB1btOF4N6OwbuMb2XgO/qGkZPRc4V9LLwJ7AXQNf1zgQeK2kdzfHr5O0qe17BrzuOdtTJC0HXEIZ8/il5v2eBy4GLpb0G2Bf4LIRPld1Sy65JCd/8VT2fttuzJ8/n4Pf+34mb7HFgr9wHMs9GSz3ZLDck8FyT4a2/59vxInn3v6qc2utMpHrTtiXFZdbmpdtPrLXlkw94gcZE9mhB+q9RWosFY/XAx8D7rU9H3iimR28BWVCydeB9frGAkp6H6WIGql4xPbdkvYDzpf0tqaVb6jXvSjpZOAfgMub0/8CnCfpxo5xj8st4HNcSZkI8zPbphS9IxWtSNoRuNP2k5KWBiY332eo124GrGB7nY5zx1HuxWeG+WzPSjqCcg/+DdiKMiHn4WaC0lbAHQv4XD1h9z32ZPc99qwdo6fkngyWezJY7slguSdwzZxHuGbOI68c7/ap/xz0mt889Ryb/l9+OgAAHbxJREFUHHpWN2NFZWOp23oWZZb1jQPOPQ3sClw+YBLJBZRxe8s0x/8p6cHmcU7nN7Z9M/A+4EJJG4+Q4XQ6Cm7bsyiF67cl/VLSdZTJO2eO8D1OA+YBt0u6ndJKeeIIrwfYGLhK0izgVmAGpWt+KAcC5w0490MWMAbU9q2UAvFA4DXARc0SQncALwGnLiBjREREDLCol+nphaV6VBq/Iv73ttlmW19304zaMSIixq1V9/9a7Qg954/nf/AW29su+JV1TNl6G1961Y0LfuFCWGulpat+5rHUbR0REREx5vTC8jqLUorHxUTSlylLAXX6ou0zauSJiIiISsZX7ZjicXGx/eEFvyoiIiJibEnxGBEREbEYjbOGxxSPEREREYtTL8yQXpTG0lI9EREREVFZWh4jIiIiFhuNu9nWaXmMiIiIiFFLy2NERETEYiIy5jEiIiIiWizFY0RERESMWrqtIyIiIhaj8dZtneIxIiIiYjHKbOuIiIiIaK20PEZEREQsLhp/3dZpeYyIiIiIUUvLY0RERMRiouYxnqR4jIiIiFicxln1mG7riIiIiBi1tDxGRERELEZZqiciIiIiWistjxERERGL0XhbqifFY0RERMRiNM5qx3RbR0RERMTopeUxIiIiYnEaZ02PaXmMiIiIWIy0iP+3wPeTdpf0S0lzJf3Dov48KR4jIiIixglJE4AvA3sAk4EDJU1elO+RbuuIiIiIxUR0fbb1nwJzbd8LIOls4O3AnYvqDVI8xiIzc+Ytv5u4lH5VOwewBvC72iF6UO7LYLkng+WeDJZ7Mlgv3ZM/qR1gJDNn3nLJxKW0xiL+tstKmtFxfJrt05rn6wC/7rj2IPBni/LNUzzGImN7zdoZACTNsL1t7Ry9JvdlsNyTwXJPBss9GSz3ZPRs7147w6KWMY8RERER48dDwHodx+s25xaZFI8RERER48fNwKaSNpS0NPAu4MJF+Qbpto7x6LQFv6SVcl8Gyz0ZLPdksNyTwXJPepTtlyR9BLgEmAB8w/acRfkesr0ov19EREREjGPpto6IiIiIUUvxGBERERGjluIxIiIiIkYtxWNEREREjFpmW8e4ImkdyuwygIdtv1QzTw3NvqYTbf+hOd4OWLq5fKvtedXCRc+QtC6wge1rm+OPAis0l8+0PbdauB4jaVXgKbd0hqmkP6F8/qeb412BfYFfAafafqFmvui+tDzGmCbpE5KO6Th1A/Aj4FLg7+qkqu7/A/+v4/gsyr34FHB0lUSVSXq7pA93HN8k6d7m8c6a2So6AVil4/gw4BnAwHFVEvUAScdImtQ8X0bSFcB/Ab+R9Oa66ar5PrA8gKQpwDnAA8AbgX+rmCsqSctjjHX7Azt1HD9ue2rT+nYV8Lk6saqaDryp4/gp23tLEnBNpUy1/T1lodw+y1Du0fLAGcAPaoSq7PW2f9Rx/KztkwAktfXfCcABwD81zw9u/n9NYDPgW8DPaoSqbKLth5vnf0VZN/AkSUsAt1XMFZWk5THGPNvPdBx+sTk3H5hYJ1F1Swzorv84QNPltsLQXzLuLW371x3H19p+3PYDNC0qLbTsgOPpHc/X6GaQHvNCR/f0bsDZtufbvov2Nrio4/k04DIA2y/XiRO1pXiMsW4FSUv1Hdj+JpTuJmClWqEqW1rSin0Hti8FkLQygwuGtli188D2RzoO1+xyll4xT9JmfQe2nwBoumzbPC72eUlbSloT2JUyBKbPcpUy1Xa5pO9L+iLlv6XLASStDWS8YwuleIyx7gfAVyW98kNd0vLAv9POrkiArwHfk7R+34lmwPtZwNerparrJkmHDjwp6TDg5xXy9IJjgR9JOljSG5rHeyl74B5bN1pVR1J+dvwCONn2fQCS9gRurRmsor8BzgXuB/7c9ovN+dcC/1grVNST7QljTGvGNn4W+ABl5p+A9YDTgaPbONsaQNKHgE9SumRFaUn6vO2vVA1WiaTXAOcDzwMzm9PbUMY+7mv7N7Wy1SRpS8p40C2aU7OBE2zPrpcqxopmzOOBtv+jdpborhSPMS5Imghs0hzOtf1czTy9oq/7OsvzFJKm0V8ozbF9ec080ZuaP0pXtf275nhp4L3AUbY3r5mtBkkrAR8G1qG0TP8U+Ajwt8Dttt9eMV5UkOIxxjRJO4903fbV3crSKyS9Z6Trtr/drSzRuySdQVmWZyi2fUg38/QKSe8CvkpZtugeSs/GN4CbgX+yPXOELx+XJF0APElZCm068BpKj8aRtjPbuoVSPMaYJumiIU4b2ApYz/aEIa6Pa5L+dZhL+wDr2G7djFFJ8xi6UFqSMhO7jffkHUOcXg84Cphge90uR+oJkmZThjLMlbQ1pWB6p+2hfta0gqRZtt/QPJ8APAKsb/uPdZNFLa37gRnji+29O48l7UhZCPtR4PAqoSqz/crnbtZ2fDdluZ4bKa0orWN7xc5jSStQuuEOA86rEqoy2z/sey5pI8oY2Z2Bz1PGDLfVC32769ieKemeNheOjb4JMtieL+nBFI7tluIxxgVJ0yk7qBg43vZPK0eqStKSlDFaH6MUje+0/cuqoXqApFUoM0ffA5wJvMn243VT1dMsy3M0MJWy48yH2jrJrMNrmq0a+6zSeWz7CxUy1fZGSb9vnguY2ByLMsShrcuitVaKxxjTJL2NslTE05TZ1ddWjlRdsw3fkZSFfHe3fX/dRPVJWoMyuP8Ayvi1qX379LaVpHMoM85PonRVzwdWKo3V/es+ttDXgBVHOG6dNg7/iZFlzGOMaZJeBh4EbmeIMW229+l6qMqae/Jb4DFefU/6Wgm2qhKsIknPUO7HGQyxAHYbW5Mk3U//vw/z6l1EbHujroeKniRptZGut/gPjdZKy2OMdbvWDtCDNqwdoAedQH+h1OpWpD62N6idoRdJ+tJI120f0a0sPeQWBv+B0cdA/tBombQ8RkS0UDOTeFhtXJIGQNLBI123/a1uZYnoVSkeY0yTNIvh16qjpV20wy1L09rB7WlNGkzSFSNctu1pXQszBkhaFtjb9jm1s/QCSRsDBwHvsr3Fgl4f40u6rWOs26t2gB60Wsfes1HcUjtAD9rN9gtDXZCUoQ+8sqbhbsCBwFuBa4DWFo+SXkeZdHYQ8Abgc8C7qoaKKtLyGGOapK8AH7f9+wW+uCUkzbQ9YpdkhKQfUxbDfmHA+a2AC9s8JlLSX1AKpD2BnwM7AhvZfrZqsEokfZBSQK8DfL95XGA7f2S01BK1A0T8L90L3CLpoNpBeshQg9pbT9LBkmZKeqZ5zFjQVo7j3EzgYknL9Z2QtAvwY+DQWqFqk/QgpUXtWmCy7XcAz7W1cGycSqkXDrJ9tO07GGG4UIx/aXmMMU/SOsAXgDWArwAv912zfW6tXLU0v/yGXXqmpcvSHExZHPyjlKJJwNaUWdin2P5OxXjVSDqa0i27B6Vb9hRgP9szqgarSNIpwL7AbMpC8hcAs9q8dJGk1YH9Ka2Pr6W0PL7X9npVg0U1KR5jXGhakD4LXE5/8Wjb76+Xqg5Jj1CK6CFbIG0f191E9Um6kTKw//4B5zcAzra9XYVYPaHZPeUwyr+XPfu25muzZlvPXSjF0p7AysAhwI9t/6FitCokLdm385CkdSnjHg8ElgfOs/3Jmvmi+1I8xpgmaQtKofQwcJTtRypHqi5jHgeTdKftyQt7bTyTdBH9a/ftCMyl7AkPtHOBfQBJH7F9asfxUvRPmtnN9hrVwlUy3M8USZtR/ij7TIVYUVGKxxjTJN0F/I3tSwacb+2yGpKesD3ijhBtI+kW29ss7LXxrJkUMizbV3UrSy8Z6Y8vSRNtP9ftTLVJutX21No5ondkqZ4Y66bYfh6yrEaHB2sH6EGbS7pjiPOipbtjjFQcSvoe0MricSRtLBwbazbDG4bUxnHUbZfiMcY0288Ps6zGhi2eHflS7QA9aPPaAcaY7WsHqGgrSUMt/dXaRfaBCcAKZCWHaKTbOsa0ZmbxA5Rxj+fbnifpvjavPybpt8DZw11v424qsXAkPWB7/do5akgX7WAZRx0DpeUxxrofUJbVOACYL+kCsv7Yc2RHlVeRdB+v/nehjmPb3rj7qeoaYW9rAUt1M0v0vLQ4xquk5THGvCyr8WppJRisWaeu0xLA/wE+BsxsFoJulQXsbY3tXbuVpZdI+qTt42vn6CWS1gce6dv2VNLrKT9rf9XGtXQjxWOMM1lWo6xp2OZ1C0ciaQng/wJ/B9wGHG/7zrqpeo+kpdq6P7qkQ4Erbd/T/GH6DeAdwP2UhbFn1sxXg6SrgUOae7IJZWz5fwCTgZ/b/kTVgNF1KR5j3JL0Cdufq52j2yRtwwhd9y395bcU8H7gKMq2c5/PYtiv1hRK0yiTz/ayvVblSFVImg1Mtf1is+3p31JWb5gKHGt7p6oBK5A0y/Ybmuf/BKxm+8OSlgZu6bsW7ZExjzGe/TVlj9q2OZH+xZ9hcCE5rbtxesJ9lFnop1AmWG0laau+i23uepO0HaVg3BdYDfgwpTu/rV7qaHXdC/i27ceBn0n6l4q5aur8GTKNsq0ntl+Q9PLQXxLjWYrHGM/aOsj748Cv+3bbafZ17ut2+3S9WFX9jPIL8I3No5OB1hWPko6n7Ff8AHAWcBwww/a3qgar72VJawNPAtMp2572mVgnUnV3SDqRspPXJsClAJJWqZoqqknxGONZW8dk/DvwZgBJO1NaXw8HpgCnAe+sF60O2+8d7pqkVnbPAh8A7qYsc3VRs2ZqW/+b6XQMMIOytuGFtufAKzvy3FszWEWHAkcC6wNv7VhDdzKlpyNaJmMeY0yTNI+hi0QBE2237g8kSbfbfmPz/MvAY7Y/3RzfZntKzXy9oGkxeQelu3Zz26+rHKnrmh2Z3kKZXDYduILyR8d6tlu90LykJYEVbT/ZcW55yu/M1q3gACBpCqXVcY7tu2rnibpa94s1xhfbK9bO0IMmSFqyKQCmAx/suNba/+YlTQTeTikYpwIrUsb5XV0zV0WHA9dTlrWaQBnfNxF4SNJltg+qGa6WprW+7/lQL2ndvxdJxwDvBmYC/yLpc7a/VjlWVNTaXyQR49hZwFWSfkdZMPwagGaJjadrBqtF0pnATpSxWv8KXA7MtX1lzVyVrUuZQDQJmAVcB3yTMiN9l2qp6vu7Ic4Z2ApYj1Jot80BlBnozzZrpv4ESPHYYikeI8YZ25+VdBmwNnCp+8emLEFpbWqjyZQJEHcBd9me3/bxfbY/BtAst7ItsAPwPsq+1k8D36mXrh7be3ceS9oROBp4lPb+9/N83zhH248366VGi6V4jBiHbN84xLm7a2TpBbanSJpEGd/3s6ZVdkVJa9n+TeV4tU0EVqLszLQyZUbtrKqJeoCk6cCnKK2Ox9v+aeVINW0k6cLmuYCNO46xvU+dWFFLJsxExLgnabvOgrpZSP1AyhaFD9reoVq4SiSdBmwBzANuAm4EbuycJNJGkt4G/COl9fWztq+tHKm6Zqb5sGxf1a0s0RtSPEbEuDfcft/Nrio72W7jJIifAGsAsykTZ24AZrvlvxSaRa8fBG5niJUc0soWkeIxIlpguOKx7ZrieQvKeMcdgC2BJ4AbbB9bM1staWUbTNIsXl1IG/gdZXmnE23/sUqwqCbFY0SMe5KeYoQlVtremiRpXWBHSgG5F7C67VbuHiJpX+B627+tnaVXSPqTIU6vBhwMLG/70C5HispSPEbEuCfpHsqOKkNqaWvSEfS3OL5I6brue8yy3co9iyX9gDLj/FnKvbiOUkzOrhqsR0m61fbU2jmiu1I8RsS4l19wg0n6Av2F0SO18/QaSRvQX1xvT9ma72bbe1aM1XM6d7SK9shSPRHRBk9Keq3tRwEkvYeyPeGvgE/bfqJqugpsf7R2hl5m+35Jy1KWMpoI9D1vHUlDjRdeFfgrWrjjTqTlMSJaQNJM4M22n2i2nzubsuDzFMre1u+sGjB6hqRPUloa1wR+SbOEEXCH7fk1s9Ui6YoBpww8DlwJnGb7xa6HiqpSPEbEuCfpNttTmudfBh6z/emB1yIk/QJ4BriIMubxJtut3NZzYUk62Pa3aueIxS9bDEVEGywpqW+YznTK3tavXKuQJ3qU7UnAW4AZlD2+z5P0c0lfk/S+quF635G1A0R3pOUxIsY9Sf8I7ElZm259YGvblrQJ8C3bO1YNGD2p+YNjG2Bn4DBgQ9sT6qbqXZmY1h4pHiOiFSRtB6wNXGr7mebcZsAKtmdWDRc9Q9I+lBnWO1IWUJ9DmZV+A2Vm+mMV4/W0LMbfHikeIyIiGpLOpVnCCLjF9guVI40ZaXlsj4z1iYiIaNjeD0DShsBbyw6O3Gn73qrBxobrageI7kjLY0REREPSisDplLGOtzenpwC3AIfY/n2tbLU021duYPva5vijwArN5TNtz60WLqrIbOuIiIh+/wrcCWxqe7+mJXJjYBZwatVk9ZwAdO51fhhlOSMDx1VJFFWl5TEiIqIh6R7bmy7stfFs4ESYzrGNkq6xvVO9dFFDWh4jIiJGR7UDVLLsgOPpHc/X6GaQ6A0pHiMiIvpdL+kYNTNl+kj6FGW5njaa1yxrBUDfXvCSJgHzqqWKatJtHRER0ZC0EmXCzNbAbc3pqcBMyoSZ1m1VKGl34EvAZyn3AcqEok8CR9q+uFa2qCPFY0RExACSNgYmN4d32v6vmnlqk7Ql8PeUhdMBZgMn2J5dL1XUkuIxIiKiQ7Mt4R7ApObUXcBPbL9UL1VE70jxGBER0ZC0DnA58AhwK2WSzFTgtcCuth+uGK8KSWdQluUZim0f0s08UV+Kx4iIiIakbwK32T5lwPkjgG1sH1wlWEWS3jHE6fWAo4AJttftcqSoLMVjREREQ9IvbE8a5tovbb++25l6iaSNKBNldgZOBk7P/t/tk6V6IiIi+j03wrVnu5aix0iaJOm7wEXAtcBk219J4dhOS9YOEBER0UNWlrTfEOcFrNTtML1A0jmUpXlOonRVzwdW6lsKs2/dx2iPdFtHREQ0mskhw7L9vm5l6RWS7qd/wox59U47tr1R10NFVSkeIyIiFpKkg21/q3aOiBpSPEZERCwkSTNtb107RzdIGvFz2p450vUYfzLmMSIiYuFpwS8ZN04a4ZqBad0KEr0hxWNERMTCa1O33W7DzaqWtGG3w0R9WaonIiJi4bWp5fF8SUsPPClpK+CKCnmishSPERERC++62gG6aCZwsaTl+k5I2gX4MXBorVBRTybMRERENCStC2xg+9rm+KPACs3lM23PrRauIklHA7sBewBvBU4B9rM9o2qwqCItjxEREf1OAFbpOD4MeIYyxvG4Kol6gO1/Bs4DbgE+D0xL4dheaXmMiIhoDFyCR9Kttqc2z6+xvVO9dHVIuoj+xcF3BOYCj/Zdt71PpWhRSWZbR0RE9Ft2wPH0judrdDNIDzlxmOfRUikeIyIi+s2TtJntu6F/32ZJk4B5VZNVYvuq4a5J+h4w7PUYn1I8RkRE9DsW+JGkz1JmGQNsA3wSOLJaqt61fe0A0X0Z8xgREdFB0pbA3wNbNKdmAyfYnl0vVW+S9IDt9WvniO5K8RgRERHDGmFvawE/sr12N/NEfSkeIyIiGpLOYPitB237kG7m6QWSRtxFxvau3coSvSHFY0REREPSO4Y4vR5wFDDB9rpdjtTTJC1l+8XaOaK7UjxGREQMQdJGlIkyOwMnA6fbfqFuqvokCZgGHATsZXutypGiy7LDTERERAdJkyR9F7gIuBaYbPsrbS8cJW0n6UvAr4ALgKuBSXVTRQ1peYyIiGhIOoeyNM9JwPeB+Z3X+9Z9bBNJxwP7Aw8AZ1G2KZxhe8OqwaKaFI8RERENSffTP2Gmb0u+Pra9UddDVSbpt8DdwCnARbafl3RvG+9FFCkeIyIiYliSJgBvAQ6kbNd4BfBmYD3bL9XMFnVkh5mIiIjGCGsaAmB75kjXx6nDgeuBQ4AJwF7AROAhSZfZPqhmuOi+tDxGREQ0FrCmoW1P61qYHiHpRGAHyuSYWcB1lGLydmAX29+pGC8qSPEYERHRkLT0cLOqJW1o+75uZ+oVkpYGtqUUkts3j6dtb141WHRdluqJiIjod35TJL2KpK0oY/3abCKwErBy83gYuLFqoqgiYx4jIiL6zQQulrS37WcBJO0CfBd4X81gtUg6DdgCmAfcROmy/oLtJ6sGi2rS8hgREdGwfTSlhfESSStI2g/4NrCv7Z/WTVfN+sAywKPAQ8CDwFNVE0VVGfMYERExgKSPAodR1nnc0/bcypGqarYk3IIy3nEHYEvgCeAG28fWzBbdl+IxIiKiIeki+hcH3xGYS2lxA8D2PpWi9QRJ61Luyw6UJXtWt71K3VTRbSkeIyIiGpL+YqTrtq/qVpZeIekI+lscX6SMeex7zLL9csV4UUGKx4iIiFGQ9D3bB9TO0W2SvkCztqPtR2rnifpSPEZERIyCpAdsr187R0RtmW0dEREREaOWdR4jIiIaI+xtLWCpbmaJ6FXpto6IiGgsYG9rbO/arSwRvSrFY0RExChIWsr2i7VzRNSWMY8RERHDUDFd0umUnVUiWi/FY0RExACStpP0JeBXwAXA1cCkuqkiekO6rSMiIhqSjgf2Bx4AzgLOA2bY3rBqsIgektnWERER/T4A3A18BbjI9vOS0soS0SHd1hEREf3WBv4Z2Bv4L0nfASZKSmNLRCPFY0RERL/DgSeAQ4CNgfMpW/M9JOnMmsEiekWKx4iIiH7rAqcAvwUuBbYBvglsC1xcL1ZE78iEmYiIiAEkLU0pGHcAtm8eT9vevGqwiB6QMRwRERGDTQRWAlZuHg8Ds6omiugRaXmMiIhoSDoN2AKYB9wE3AjcaPvJqsEiekjGPEZERPRbH1gGeBR4iLKrzFNVE0X0mLQ8RkREdJAkSuvjDs1jS8oM7BtsH1szW0QvSPEYERExBEnrAjtSCsi9gNVtr1I3VUR9KR4jIiIako6gv8XxReD6jscs2y9XjBfREzLbOiIiot8GwDnAUbYfqZwloiel5TEiIiIiRi2zrSMiIiJi1FI8RkRERMSopXiMiNaRNF/SbZJmSzpH0nL/i+/1TUnvbJ5/XdLkEV67i6Qd/gfvcb+kNUZ7fsBr/rCQ7/VpSR9b2IwR0R4pHiOijZ6zPcX2lsALwIc6L0r6H00mtP0B23eO8JJdKLN4IyLGrBSPEdF21wCbNK2C10i6ELhT0gRJJ0i6WdIdkg6DsoC0pFMl/VLSz4DX9H0jSVdK2rZ5vrukmZJul3SZpA0oRepRTavnTpLWlPTD5j1ulrRj87WrS7pU0hxJXwe0oA8h6XxJtzRf88EB105uzl8mac3m3MaSftJ8zTWSJi2KmxkR41+W6omI1mpaGPcAftKc2hrY0vZ9TQH2tO03SVoGuE7SpcBU4PXAZGAt4E7gGwO+75rA14Cdm++1mu0nJP078AfbJzavOxM42fa1ktYHLgE2B44FrrX9GUlvAw4Zxcd5f/MeE4GbJf3Q9uPA8sAM20dJOqb53h8BTgM+ZPseSX8G/Bsw7X9wGyOiZVI8RkQbTZR0W/P8GuB0Snfyz23f15x/K7BV33hGYGVgU2Bn4Czb84GHJV0+xPffDri673vZfmKYHG8GJpfd8ABYSdIKzXvs13ztf0p6chSf6QhJf9k8X6/J+jjwMvC95vx3gXOb99gBOKfjvZcZxXtERKR4jIhWes72lM4TTRH1TOcp4HDblwx43Z6LMMcSwHa2/zhEllGTtAulEN3e9rOSrgSWHeblbt73qYH3ICJiNDLmMSJiaJcAfy1pKQBJm0laHrgaOKAZE7k2sOsQX3sjsLOkDZuvXa05Pw9YseN1lwKH9x1I6ivmrgYOas7tAay6gKwrA082heMkSstnnyWAvtbTgyjd4b8H7pO0f/MekvTGBbxHRASQ4jEiYjhfp4xnnClpNvBVSm/NecA9zbVvAzcM/ELbjwEfpHQR305/t/FFwF/2TZgBjgC2bSbk3En/rO/jKMXnHEr39QMLyPoTYElJdwGfpxSvfZ4B/rT5DNOAzzTn3w0c0uSbA7x9FPckIiLbE0ZERETE6KXlMSIiIiJGLcVjRERERIxaiseIiIiIGLUUjxERERExaikeIyIiImLUUjxGRERExKileIyIiIiIUftvLAdqbRLUmNMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "TLzJ38Tc6Orw",
        "outputId": "51566883-7a3f-4a9a-f0c5-643a04af0613"
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "\n",
        " \n",
        "data = {'Logistic Regression':95, 'Linear SVM': 96, 'Kernel SVM': 94,'Decision Tree': 87, 'Random Forest': 92, 'Neural Network': 93,  \"Conv 1-D\": 96} \n",
        "courses = list(data.keys()) \n",
        "values = list(data.values()) \n",
        "\n",
        "fig = plt.figure(figsize = (10, 5)) \n",
        "\n",
        "\n",
        "plt.bar(courses, values, color ='maroon', width = 0.4) \n",
        "\n",
        "plt.xlabel(\"Algorithms\") \n",
        "plt.ylabel(\"Accuracy Percentage\") \n",
        "plt.title(\"Accucary Obtained Using Various Algorithms\") \n",
        "plt.show() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTFk--WD6Xdu"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}